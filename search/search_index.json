{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Duy M. Nguyen's notebook","text":"<p>M\u1ee5c \u0111\u00edch c\u1ee7a trang blog n\u00e0y l\u00e0 \u0111\u1ec3 c\u00e1 nh\u00e2n m\u00ecnh note l\u1ea1i m\u1ecdi th\u1ee9 m\u00e0 m\u00ecnh th\u1ea5y c\u1ea7n thi\u1ebft cho b\u1ea3n th\u00e2n, bao g\u1ed3m nh\u1eefng th\u1ee9 li\u00ean quan \u0111\u1ebfn c\u00f4ng vi\u1ec7c engineer c\u1ee7a m\u00ecnh, t\u1eeb m\u1ea5y c\u00e1i nh\u1ecf nh\u01b0 c\u00e1c thu\u1eadt to\u00e1n thi\u1ebfu nhi, \u0111\u1ebfn m\u1ea5y c\u00e1i l\u1edbn h\u01a1n nh\u01b0 System Design, hay c\u00e1c thu\u1eadt to\u00e1n Machine Learning,... (ch\u1eafc ch\u1ee7 y\u1ebfu s\u1ebd l\u00e0 nh\u1eefng c\u00e1i nh\u1ecf, v\u00ec m\u1ea5y c\u00e1i to m\u00ecnh l\u01b0\u1eddi vi\u1ebft )</p> <p>Ngo\u00e0i ra nh\u1eefng th\u1ee9 linh tinh nh\u01b0 c\u1ea3m nh\u1eadn c\u00e1 nh\u00e2n sau khi xem m\u1ed9t b\u1ed9 phim, review v\u1ec1 m\u1ed9t m\u00f3n \u0111\u1ed3 linh tinh n\u00e0o \u0111\u1ea5y mua tr\u00ean s\u00e0n S hay s\u00e0n L, hay c\u1ea3m x\u00fac sau m\u1ed9t chuy\u1ebfn \u0111i ch\u01a1i \u1edf \u0111\u00e2u \u0111\u1ea5y th\u00ec c\u00f3 th\u1ec3 c\u0169ng \u0111\u01b0\u1ee3c ghi l\u00ean \u0111\u00e2y lu\u00f4n :v</p> <p>L\u1eddi nh\u1eafn nh\u1ee7</p> <p>M\u00ecnh bi\u1ebft l\u00e0 tr\u00ecnh \u0111\u1ed9 c\u1ee7a m\u00ecnh c\u00f2n g\u00e0, n\u00ean nh\u1eefng b\u00e0i post v\u1ec1 c\u00f4ng ngh\u1ec7 c\u1ee7a m\u00ecnh m\u00e0 xu\u1ea5t hi\u1ec7n ki\u1ebfn th\u1ee9c g\u00ec \u0111\u1ea5y sai ho\u1eb7c l\u1ed7i th\u1eddi l\u00e0 chuy\u1ec7n b\u00ecnh th\u01b0\u1eddng. N\u1ebfu m\u00e0 ph\u00e1t hi\u1ec7n ra m\u00ecnh sai ch\u1ed7 n\u00e0o th\u00ec mong b\u1ea1n \u0111\u1ecdc hoan h\u1ec9 nh\u1eafc nh\u1edf m\u00ecnh theo c\u00e1c k\u00eanh contact m\u00ecnh \u0111\u1ec3 g\u00f3c d\u01b0\u1edbi b\u00ean ph\u1ea3i c\u1ee7a page (m\u00ecnh r\u1ea5t mong \u0111i\u1ec1u n\u00e0y x\u1ea3y ra v\u00ec sai \u1edf \u0111\u00e2u th\u00ec b\u1ea3n th\u00e2n n\u00ean bi\u1ebft c\u00e0ng s\u1edbm c\u00e0ng t\u1ed1t \u0111\u1ec3 m\u00e0 s\u1eeda )</p> <p>G\u00f3c xin x\u1ecf</p> <p>Ngo\u00e0i trang blog n\u00e0y th\u00ec m\u00ecnh c\u00f2n m\u1edbi t\u1eadp ch\u01a1i tiktok v\u1edbi m\u1ed9t k\u00eanh v\u1ec1 thu\u1eadt to\u00e1n. Anh em cho xin m\u1ed9t follow \u1ee7ng h\u1ed9 l\u1ea5y tinh th\u1ea7n nh\u00e9 </p> <p> chikodevn</p> <p>B\u00e2y gi\u1edd anh em c\u00f3 th\u1ec3 b\u1ea5m v\u00e0o \u0111\u00e2y \u0111\u1ec3 b\u1eaft \u0111\u1ea7u \u0111\u1ecdc c\u00e1c b\u00e0i vi\u1ebft c\u1ee7a m\u00ecnh nh\u00e9. C\u1ea3m \u01a1n anh em nhi\u1ec1u </p>"},{"location":"blog/","title":"Recent Posts","text":""},{"location":"blog/algorithms-for-rate-limiting/","title":"Algorithms for rate limiting","text":"<p>In this post, we're going to discuss what a rate limiter is and which algorithms have been used for rate limiters.</p>"},{"location":"blog/algorithms-for-rate-limiting/#rate-limiter-overview","title":"Rate limiter overview","text":""},{"location":"blog/algorithms-for-rate-limiting/#what-is-a-rate-limiter","title":"What is a rate limiter?","text":"<p>In a network system, a rate limiter is used to control the rate of traffic sent by a client or a service.</p> <p>In HTTP world, a rate limiter limits the number of client requests allowed to be sent over a specified period.</p> <p>If the API request count exceeds the threshold defined by the rate limiter, all the excess calls are blocked.</p> Example <ul> <li>A user can write no more than 2 posts per second</li> <li>You can create a maximum of 100 accounts per day from the same IP address</li> <li>You can claim rewards no more than 5 times per week from the same device</li> </ul>"},{"location":"blog/algorithms-for-rate-limiting/#benefits-of-using-a-rate-limiter","title":"Benefits of using a rate limiter","text":""},{"location":"blog/algorithms-for-rate-limiting/#common-rate-limiting-algorithms","title":"Common rate limiting algorithms","text":"<p>This section will only provide a high-level understanding for popular algorithms for rate limiting.<sup>1</sup></p>"},{"location":"blog/algorithms-for-rate-limiting/#fixed-window-counter","title":"Fixed window counter","text":"<p>The fixed window counter algorithm divides the timeline into fixed-size time windows, and assigns a counter for each window.</p> <p>Each request increments the counter by some value based on the relative cost of the request.</p> <p>Once the counter reaches the threshold, subsequent requests are blocked until the new time window begins.</p> Example <p>In this example, the time unit is 1 second and the system allows a maximum of 3 requests per second.</p> <p>In each 1-second time window, if more than 3 requests are received, subsequent requests arriving within the same time window are dropped.</p> <p></p> <p>This algorithm is simple to implement. A major problem with it is that a burst of traffic at the beginning or end of time windows could allow excess requests over the threshold to go through.</p> Example <p>The rate limiter allows a maximum of 5 requests per minute, and the available quota resets at the top of each minute.</p> <p>There are five requests between 2:00:00 and 2:01:00 and five more requests between 2:01:00 and 2:02:00. For the 1-minute window between 2:00:30 and 2:01:30, 10 requests go through. That is twice as many as the allowed number of requests.</p> <p></p>"},{"location":"blog/algorithms-for-rate-limiting/#sliding-window-log","title":"Sliding window log","text":"<p>The sliding window log algorithm keeps track of the timestamps of individual requests in a log. The log is usually kept in a cache, such as sorted sets in Redis.</p> <p>When a new request arrives, the log is checked for requests within the window. The check removes all outdated timestamps older than the start of the current time window from the logs and adds the new request to the log. The new request is allowed if the number of existing requests within the window is below the limit.</p> Example <p>The rate limiter allows 2 requests per minute.</p> <p></p> <ol> <li>The log is empty when a new request arrives at 1:00:01. The request is allowed.</li> <li>A new request arrives at 1:00:30, the timestamp is inserted into the log. Now the log size is 2. It is below the threshold of 2. This request is also allowed.</li> <li>Another request arrives at 1:00:50, and the timestamp is inserted into the log. The new log size is 3, which is larger than the threshold. This request is rejected.</li> <li>The final request arrives at 1:01:40. Requests in the range \\([\\)1:00:40, 1:01:40\\()\\) are in the latest time window, but requests sent before 1:00:40 are outdated. Two outdated timestamps, 1:00:01 and 1:00:30, are removed from the log. After clearing the old log entries, the log size is 2, and the request is accepted.</li> </ol> <p>This algorithm ensures that in any rolling window, requests will not exceed the limit.</p> <p>However, the algorithm consumes a lot of memory. It maintains a log of timestamps, even for requests that are rejected.</p>"},{"location":"blog/algorithms-for-rate-limiting/#sliding-window-counter","title":"Sliding window counter","text":"<p>The sliding window counter algorithm is a more efficient variation of the sliding window log algorithm. It is a hybrid that combines the fixed window counter and sliding window log.</p> <p>Instead of maintaining a log of request timestamps, it calculates the weighted counter for the previous time window. When a new request arrives, the counter is adjusted based on the weight, and the request is allowed if the total is below the limit.</p> <p>The number of requests in the rolling window is calculated using the following formula:</p> \\[ \\tag{1} \\begin{array}{c} \\small\\text{requests in} \\\\ \\small\\text{current window} \\end{array} ~ + ~  \\begin{array}{c} \\small\\text{requests in the} \\\\ \\small\\text{previous window} \\end{array} ~ \\times ~ \\begin{array}{c} \\small\\text{overlap percentage of the} \\\\ \\small\\text{rolling window and previous window} \\end{array} \\] Example <p>The rate limiter allows a maximum of 7 requests per minute. There are 5 requests in the previous minute and 3 in the current minute. For a new request that arrives at 30% (18 seconds) into the current minute, </p> <p>Using formula \\((1)\\), we get \\(3 + 5 \\times 0.7 = 6.5\\) requests. Depending on the use case, the number can either be rounded up or down. In this example, it is rounded down to 6.</p> <p></p> <p>Since the rate limiter allows 7 requests per minute, the current request can go through.</p> <p>Note</p> <p>There is another way to implement this algorithm that is more complicated. Instead of computing a weighted counter for the previous window, it uses a counter for each time slot within the window. We will not discuss this other implementation here.</p> <p>This algorithm reduces storage and processing requirements compared to the sliding window log algorithm.</p> <p>However, it may still allow bursts of requests to slip through. It is an approximation of the actual rate because it assumes requests in the previous window are evenly distributed.</p>"},{"location":"blog/algorithms-for-rate-limiting/#token-bucket","title":"Token bucket","text":"<p>The token bucket algorithm is widely used for rate limiting. It is simple, well understood, and commonly used by large tech companies.</p> <p>The token bucket algorithm uses a \"bucket\" to hold a token. The tokens represent the allowed number of requests. The bucket is initially filled with tokens, and tokens are added at a fixed rate over time.</p> <p>When a request arrives, it consumes a token from the bucket, and the request is allowed if there are enough tokens.</p> Example <p>Here, the token capacity is 4. The refiller puts 2 tokens into the bucket every second. Once the bucket is full, extra tokens will overflow.</p> <p></p> <p>Each request consumes one token. When a request arrives, we check if there are enough tokens in the bucket. If there are enough tokens, we take one token out for each request, and the request goes through. If there are not enough tokens, the request is dropped.</p> <p></p> <p>The following diagram illustrates how token consumption, refill, and rate limiting logic work. In this example, the token bucket size is 4, and the refill is 4 per 1 minute.</p> <p></p> <p>The token bucket algorithm takes two parameters:</p> <ul> <li>Bucket size: The maximum number of tokens allowed in the bucket.</li> <li>Refill rate: number of tokens put into the bucket every second.</li> </ul> <p>How many buckets do we need? This depends on the rate-limiting rules.</p> <p>Example</p> <ul> <li> <p>It is usually necessary to have different buckets for different API endpoints. For instance, if a user is allowed to make 1 post per second, add 150 friends per day, and like 5 posts per second, 3 buckets are required for each user.</p> </li> <li> <p>If we need to throttle requests based on IP addresses, each IP address requires a bucket.</p> </li> <li> <p>If the system allows a maximum of 10000 requests per second, it makes sense to have a global bucket shared by all requests.</p> </li> </ul> <p>This algorithm allows a smooth distribution of requests and can handle burst of requests up to the bucket's capacity. It is memory efficient and relatively easy to implement.</p>"},{"location":"blog/algorithms-for-rate-limiting/#leaky-bucket","title":"Leaky bucket","text":"<p>The leaky bucket algorithm uses a \"bucket\" metaphor but processes requests differently.</p> <p>Requests enter the bucket and are processed at a fixed rate, simulating a \"leak\" in the bucket. If the bucket becomes full, new requests are discarded until there is space available.</p> <p>It is usually implemented with a FIFO queue. The algorithm works as follows:</p> <ul> <li>When a request arrives, the system checks if the queue is full. If it is not full, the request is added to the queue.</li> <li>Otherwise, the request is dropped.</li> <li>Requests are pulled from the queue and processed at regular intervals.</li> </ul> <p></p> <p>The leaky bucket algorithm takes the following two parameters:</p> <ul> <li>Bucket size: It is equal to the queue size. The queue holds the requests to be processed at a fixed rate.</li> <li>Outflow rate: It defines how many requests can be processed at a fixed rate, usually in requests per second.</li> </ul> <p>This algorithm is memory efficient given the limited queue size. Requests are processed at a fixed rate. It smooths out request bursts and enforces a consistent rate of processing. It is suitable for use cases where a stable outflow rate is required.</p> <p>However, a burst of requests would fill up the queue with old requests, and if they are not processed in time, recent requests will be rate limited. It may result in longer waiting times for requests during high-traffic periods.</p>"},{"location":"blog/algorithms-for-rate-limiting/#summary","title":"Summary","text":"<p>Five common rate limiting algorithms:</p> <ul> <li>Fixed Window Counter: Divides time into fixed windows and counts the number of requests within each window.</li> <li>Sliding Window Log: Keeps a log of request timestamps and continuously updates it to track requests within a sliding time window.</li> <li>Sliding Window Counter: Combines fixed and sliding window approaches by calculating a weighted counter from previous and current windows to regulate request rates.</li> <li>Token Bucket: Maintains a bucket of tokens, where each token allows a request. Tokens are added at a fixed rate, and requests are processed if enough tokens are available.</li> <li>Leaky Bucket: Processes requests at a constant rate by adding them to a queue and handling them one-by-one, simulating a fixed outflow rate.</li> </ul> <p>Each of these rate limiting algorithms has its strengths and weaknesses. The choice of the appropriate algorithm depends on the specific requirements of the system and its desired behavior under various conditions.</p> <ol> <li> <p>ByteByteGo, Rate Limiting Fundamentals \u21a9</p> </li> </ol>"},{"location":"blog/cap-theorem/","title":"The CAP theorem","text":"<p>In this post, we're going to explore what the CAP theorem is and its relevance in today\u2019s distributed systems.</p> <p>To be more intuitive, let's use a real-life example to illustrate the concepts:<sup>1</sup></p> <p>Tiny Bank example</p> <p>Let's say we have a tiny bank with exactly two ATMs connected over a network. The ATMs support three operations: deposit, withdraw, and check balance. There is no central database to keep the account balance, it is stored on both ATMs. No matter what happens, the balance should never go below zero.</p> <p> </p>","tags":["CAP theorem"]},{"location":"blog/cap-theorem/#what-is-the-cap-theorem","title":"What is the CAP theorem?","text":"<p>In database theory, the CAP theorem states that any distributed data store can provide only two of the following three guarantees:</p> <ul> <li> <p>Consistency: Refers to the property of a system where all nodes have a consistent view of the data. It means all clients see the same data at the same time no matter which node they connect to.</p> Tiny Bank example <p>Consistency means that the balance is always the same on both ATMs. When a customer uses an ATM, no matter which one they are using, they always see the same balance.</p> </li> <li> <p>Availability: Refers to the ability of a system to respond to requests from users at all times.</p> Tiny Bank example <p>Availability means that clients can always perform operations at any ATM.</p> </li> <li> <p>Partition tolerance: Refers to the ability of a system to continue operating even if there is a network partition.</p> Tiny Bank example <p>Partition tolerance means that the bank should remain operational even if the two ATMs are unable to communicate with each other.</p> </li> </ul> <p>Note</p> <p>In practice, during a network partition, a system must choose between consistency and availability.</p> <p>If the system prioritizes consistency, it may become unavailable until the partition is resolved.</p> <p>Conversely, if the system prioritizes availability, it may allow updates to the data, potentially resulting in data inconsistencies until the partition is resolved.</p> <p> </p> <p>We will discuss this in more detail in the next section.</p>","tags":["CAP theorem"]},{"location":"blog/cap-theorem/#cap-theorem-nosql-database-types","title":"CAP theorem NoSQL database types","text":"<p>NoSQL databases are ideal for distributed network applications. Unlike their vertically scalable SQL (relational) counterparts, NoSQL databases are horizontally scalable and distributed by design.<sup>2</sup></p> <p>Today, NoSQL databases are classified based on the two CAP characteristics they support:</p>","tags":["CAP theorem"]},{"location":"blog/cap-theorem/#cp-database","title":"CP database","text":"<p>A CP database delivers consistency and partition tolerance at the expense of availability.</p> <p>When a partition occurs between any two nodes, the system has to shut down the non-consistent node (i.e., make it unavailable) until the partition is resolved.</p> Tiny Bank example <p>If there is a network partition and the ATMs are unable to communicate with each other, and the bank prioritizes consistency, the ATMs may refuse to process deposits or withdrawals until the partition is resolved. This ensures that the balance remains consistent, but the system is unavailable to customers.</p> <p> If a network partition occurs, customers cannot make deposits or withdrawals, ensuring the system's consistency. </p>","tags":["CAP theorem"]},{"location":"blog/cap-theorem/#ap-database","title":"AP database","text":"<p>An AP database delivers availability and partition tolerance at the expense of consistency.</p> <p>When a partition occurs, all nodes remain available but those at the wrong end of a partition might return an older version of data than others. (When the partition is resolved, the AP databases typically resync the nodes to repair all inconsistencies in the system.)</p> Tiny Bank example <p>If there is a network partition and the ATMs are unable to communicate with each other, and the bank prioritizes availability, the ATM may allow deposits and withdrawals to occur, but the balance may become inconsistent until the partition is resolved.</p> <p> If a network partition occurs, the balance may become inconsistent when customers make deposits or withdrawals. </p>","tags":["CAP theorem"]},{"location":"blog/cap-theorem/#ca-database","title":"CA database","text":"<p>A CA database delivers consistency and availability across all nodes. It can\u2019t do this if there is a partition between any two nodes in the system. Therefore, it can\u2019t deliver fault tolerance.</p> <p>In practice, this means that for a CA database to function correctly, it must operate in an environment where network partitions are impossible or extremely rare.</p> Tiny Bank example <p>If the system requires both consistency and availability, then network partitions must not occur. If a network partition does happen, the system will become unavailable, users will experience downtime.</p> <p>Note</p> <p>In a distributed system, partitions can\u2019t be avoided. So, while we can discuss a CA distributed database in theory, for all practical purposes, a CA distributed database can\u2019t exist. This doesn\u2019t mean you can\u2019t have a CA database for your distributed application if you need one. Many relational databases, such as PostgreSQL, deliver consistency and availability in a single-node setup or with replication, assuming no network partitions occur.<sup>2</sup></p>","tags":["CAP theorem"]},{"location":"blog/cap-theorem/#summary","title":"Summary","text":"<p>The CAP theorem is a useful tool for understanding the high-level trade-offs to consider during a network partition. While it is a good starting point, it does not provide a complete picture of the trade-offs involved in designing a comprehensive distributed system.</p> <p>Despite numerous advancements in NoSQL databases and other distributed systems, the CAP theorem remains relevant today as a fundamental tradeoff in distributed system designs.<sup>3</sup></p> <p>Note</p> <p>The CAP theorem assumes 100% availability or 100% consistency. In the real world, there are degrees of consistency and availability that distributed system designers must carefully consider.</p> Tiny Bank Example <p>During a network partition, the ATMs could allow only balance inquiries to be processed, while deposits or withdrawals are blocked. This maintains the system's consistency but is not 100% unavailable to customers (customers can still perform balance inquiries).</p> <p> If a network partition occurs, the ATMs could allow only balance inquiries to be processed, while deposits or withdrawals are blocked. </p> <ol> <li> <p>ByteByteGo, CAP Theorem Simplified \u21a9</p> </li> <li> <p>IBM, What is the CAP theorem? \u21a9\u21a9</p> </li> <li> <p>RR, CAP theorem \u2014 Is it still relevant? \u21a9</p> </li> </ol>","tags":["CAP theorem"]},{"location":"blog/hadoop-overview/","title":"Gi\u1edbi thi\u1ec7u v\u1ec1 Apache Hadoop","text":"<p>B\u00e0i vi\u1ebft n\u00e0y gi\u1edbi thi\u1ec7u c\u00e1i nh\u00ecn t\u1ed5ng quan nh\u1ea5t v\u1ec1 Apache Hadoop, bao g\u1ed3m ki\u1ebfn tr\u00fac, c\u00e1ch th\u1ee9c ho\u1ea1t \u0111\u1ed9ng c\u1ee7a n\u00f3.</p> <p>Apache Hadoop l\u00e0 m\u1ed9t framework d\u00f9ng \u0111\u1ec3 l\u01b0u tr\u1eef v\u00e0 x\u1eed l\u00fd d\u1eef li\u1ec7u l\u1edbn. Hadoop s\u1eed d\u1ee5ng m\u1ed9t cluster g\u1ed3m nhi\u1ec1u nodes \u0111\u1ec3 x\u1eed l\u00fd d\u1eef li\u1ec7u song song thay v\u00ec ch\u1ec9 s\u1eed d\u1ee5ng m\u1ed9t m\u00e1y duy nh\u1ea5t, c\u1ea3i thi\u1ec7n t\u1ed1c \u0111\u1ed9 khi x\u1eed l\u00fd d\u1eef li\u1ec7u l\u1edbn.<sup>1</sup></p>","tags":["Hadoop"]},{"location":"blog/hadoop-overview/#tong-quan-ve-hadoop","title":"T\u1ed5ng quan v\u1ec1 Hadoop","text":"<p>Hadoop s\u1eed d\u1ee5ng h\u00e0ng tr\u0103m th\u1eadm ch\u00ed h\u00e0ng ng\u00e0n servers l\u00e0m vi\u1ec7c c\u00f9ng nhau \u0111\u1ec3 l\u01b0u tr\u1eef v\u00e0 x\u1eed l\u00fd d\u1eef li\u1ec7u l\u1edbn.</p> <p>Hadoop bao g\u1ed3m 4 modules ch\u00ednh<sup>1</sup>:</p> <ul> <li>Hadoop Distributed File System (HDFS) l\u00e0 m\u1ed9t distributed file system, d\u00f9ng \u0111\u1ec3 l\u01b0u tr\u1eef data.</li> <li>Yet Another Resource Negotiator (YARN) l\u00e0 module \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00e0 monitor c\u00e1c nodes. N\u00f3 c\u00f3 t\u00e1c d\u1ee5ng schedules c\u00e1c jobs v\u00e0 tasks, \u0111\u00f3ng vai tr\u00f2 nh\u01b0 m\u1ed9t resource manager.</li> <li>MapReduce l\u00e0 module th\u1ef1c thi\u1ec7n x\u1eed l\u00fd data. </li> <li>Hadoop Common cung c\u1ea5p c\u00e1c th\u01b0 vi\u1ec7n java \u0111\u1ec3 c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng \u1edf c\u00e1c module kh\u00e1c.</li> </ul> <p>M\u1ed9t Hadoop cluster bao g\u1ed3m m\u1ed9t ho\u1eb7c nhi\u1ec1u master nodes v\u00e0 nhi\u1ec1u slave nodes, c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c scale out b\u1eb1ng c\u00e1ch th\u00eam nodes v\u00e0o cluster.</p> <p>C\u00e1c ph\u1ea7n ti\u1ebfp theo c\u1ee7a b\u00e0i vi\u1ebft s\u1ebd n\u00f3i k\u1ef9 h\u01a1n v\u1ec1 ki\u1ebfn tr\u00fac v\u00e0 c\u00e1ch ho\u1ea1t \u0111\u1ed9ng c\u1ee7a Hadoop.</p>","tags":["Hadoop"]},{"location":"blog/hadoop-overview/#kien-truc-hadoop","title":"Ki\u1ebfn tr\u00fac Hadoop","text":"<p>Ki\u1ebfn tr\u00fac c\u1ee7a Hadoop c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c chia th\u00e0nh 4 layers:</p> T\u1ed5ng quan v\u1ec1 ki\u1ebfn tr\u00fac c\u1ee7a Hadoop","tags":["Hadoop"]},{"location":"blog/hadoop-overview/#distributed-storage-layer","title":"Distributed Storage Layer","text":"<p>Th\u1eb1ng n\u00e0y ch\u00ednh l\u00e0 th\u1eb1ng HDFS, bao g\u1ed3m m\u1ed9t ho\u1eb7c nhi\u1ec1u master nodes (hay c\u00f2n g\u1ecdi l\u00e0 NameNode) v\u00e0 nhi\u1ec1u slave nodes (hay c\u00f2n g\u1ecdi l\u00e0 DataNode). M\u1ed7i node c\u00f3 b\u1ed9 nh\u1edb c\u1ee7a ri\u00eang n\u00f3. Data \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o s\u1ebd \u0111\u01b0\u1ee3c chia th\u00e0nh c\u00e1c data blocks sau \u0111\u00f3 \u0111\u01b0\u1ee3c l\u01b0u \u1edf HDFS distributed storage layer. Ngo\u00e0i ra, HDFS l\u01b0u th\u00eam 3 b\u1ea3n copies c\u1ee7a data \u1edf tr\u00ean kh\u1eafp cluster. NameNode s\u1ebd l\u01b0u th\u00f4ng tin v\u1ec1 c\u00e1c data block c\u1ee5 th\u1ec3 v\u00e0 c\u00e1c replicas c\u1ee7a n\u00f3 \u0111\u01b0\u1ee3c l\u01b0u \u1edf \u0111\u00e2u trong cluster.</p>","tags":["Hadoop"]},{"location":"blog/hadoop-overview/#cluster-resource-management","title":"Cluster Resource Management","text":"<p>Th\u1eb1ng n\u00e0y ch\u00ednh l\u00e0 th\u1eb1ng YARN. N\u00f3 s\u1ebd ch\u1ec9 \u0111\u1ecbnh resource cho c\u00e1c frameworks kh\u00e1c \u0111\u01b0\u1ee3c vi\u1ebft cho Hadoop. M\u1ed9t s\u1ed1 framework nh\u01b0 Apache Pig, Hive, Giraph, Zookeeper. N\u00f3 c\u0169ng ch\u1ec9 \u0111\u1ecbnh resource cho ch\u00ednh th\u1eb1ng MapReduce lu\u00f4n.</p>","tags":["Hadoop"]},{"location":"blog/hadoop-overview/#processing-framework-layer","title":"Processing Framework Layer","text":"<p>Layer n\u00e0y bao g\u1ed3m c\u00e1c frameworks th\u1ef1c hi\u1ec7n c\u00e1c b\u01b0\u1edbc x\u1eed l\u00fd data. C\u00e1c framework nh\u01b0 Spark, Storm hay Tez b\u00e2y gi\u1edd c\u00f3 th\u1ec3 x\u1eed l\u00fd real-time, t\u0103ng hi\u1ec7u qu\u1ea3 cho h\u1ec7 th\u1ed1ng.</p>","tags":["Hadoop"]},{"location":"blog/hadoop-overview/#application-programming-interface","title":"Application Programming Interface","text":"<p>Nh\u01b0 t\u00ean g\u1ecdi c\u1ee7a n\u00f3, layer n\u00e0y g\u1ed3m c\u00e1c API \u0111\u1ec3 c\u00e1c l\u1eadp tr\u00ecnh vi\u00ean s\u1eed d\u1ee5ng.</p> <p>Chi ti\u1ebft v\u1ec1 c\u00e1ch ho\u1ea1t \u0111\u1ed9ng c\u1ee7a t\u1eebng th\u00e0nh ph\u1ea7n s\u1ebd \u0111\u01b0\u1ee3c n\u00f3i k\u1ef9 h\u01a1n \u1edf m\u1ed9t b\u00e0i vi\u1ebft kh\u00e1c.</p> <ol> <li> <p>AWS, What is Hadoop \u21a9\u21a9</p> </li> </ol>","tags":["Hadoop"]},{"location":"blog/load-balancing-algorithms/","title":"Load Balancing Algorithms","text":"<p>In this post, we'll provide a comprehensive overview of load balancing algorithms, discussing how they work and their pros and cons.</p> <p>A load balancer is a device that distributes network traffic across multiple servers. A load balancing algorithm is the logic a load balancer uses to distribute network traffic among these servers.<sup>1</sup></p> <p>There are two main categories of algorithms: static and dynamic. Let's explore each category and dive deeper into the major specific algorithms.<sup>2</sup></p>","tags":["Load Balancing"]},{"location":"blog/load-balancing-algorithms/#static-algorithms","title":"Static Algorithms","text":"<p>Static load balancing algorithms distribute requests to servers without taking into account the servers' real-time conditions and performance metrics.</p>","tags":["Load Balancing"]},{"location":"blog/load-balancing-algorithms/#round-robin","title":"Round Robin","text":"<p>Description</p> <p>Distributes requests evenly among servers in sequence.</p> <p>Pros</p> <ul> <li>Easy to implement and understand.</li> </ul> <p>Cons</p> <ul> <li>Can potentially overload servers if they are not properly monitored.</li> </ul>","tags":["Load Balancing"]},{"location":"blog/load-balancing-algorithms/#sticky-round-robin","title":"Sticky Round Robin","text":"<p>Description</p> <p>An extension of round robin that tries to route subsequent requests from the same user to the same server.</p> <p>Pros</p> <ul> <li>Improves performance by keeping related data on the same server.</li> </ul> <p>Cons</p> <ul> <li>Uneven loads can easily occur since newly arriving users are assigned randomly.</li> </ul>","tags":["Load Balancing"]},{"location":"blog/load-balancing-algorithms/#weighted-round-robin","title":"Weighted Round Robin","text":"<p>Description</p> <p>Allows admins to assign different weights or priorities to different servers. Servers with higher weights receive higher number of requests.</p> <p>Pros</p> <ul> <li>Accounts for heterogeneous server capabilities.</li> </ul> <p>Cons</p> <ul> <li>Weights must be manually configured, which is less adaptive to real-time changes.</li> </ul>","tags":["Load Balancing"]},{"location":"blog/load-balancing-algorithms/#hash-based-algorithms","title":"Hash-Based Algorithms","text":"<p>Description</p> <p>Uses a hash function to map incoming requests to the backend servers. The hash function often uses the client's IP address or the requested URL as input for determining where to route each request.</p> <p>Pros</p> <ul> <li>Can evenly distribute requests if the function is chosen wisely.</li> </ul> <p>Cons</p> <ul> <li>Selecting an optimal hash function can be challenging.</li> </ul>","tags":["Load Balancing"]},{"location":"blog/load-balancing-algorithms/#dynamic-algorithms","title":"Dynamic Algorithms","text":"<p>Dynamic load balancing algorithms adapt in real-time by taking active performance metrics and server conditions into account when distributing requests.</p>","tags":["Load Balancing"]},{"location":"blog/load-balancing-algorithms/#least-connections","title":"Least Connections","text":"<p>Description</p> <p>Sends each new request to the server currently with the least number of active connections or open requests.</p> <p>Pros</p> <ul> <li>New requests are adaptively routed to where there is the most remaining capacity.</li> </ul> <p>Cons</p> <ul> <li>Requires actively tracking the number of ongoing connections on each backend server.</li> <li>Load can unintentionally concentrate on certain servers if connections pile up unevenly.</li> </ul>","tags":["Load Balancing"]},{"location":"blog/load-balancing-algorithms/#least-response-time","title":"Least Response Time","text":"<p>Description</p> <p>Sends incoming requests to the server with the lowest current latency or fastest response time. Latency for each server is continuously measured and factored in.</p> <p>Pros</p> <ul> <li>Highly adaptive and reactive.</li> </ul> <p>Cons</p> <ul> <li>Requires constant monitoring, which incurs significant overhead and introduces complexity.</li> <li>Does not consider how many existing requests each server already has.</li> </ul>","tags":["Load Balancing"]},{"location":"blog/load-balancing-algorithms/#summary","title":"Summary","text":"<p>There are clear tradeoffs between simple static algorithms and more adaptive dynamic ones. Static algorithms like round robin work well for stateless applications. Dynamic algorithms help optimize response times and availability for large, complex applications.<sup>2</sup></p> <ol> <li> <p>Cloudflare, Types of load balancing algorithms \u21a9</p> </li> <li> <p>ByteByteGo, Top 6 Load Balancing Algorithms Every Developer Should Know \u21a9\u21a9</p> </li> </ol>","tags":["Load Balancing"]},{"location":"course/","title":"Courses","text":""},{"location":"course/ml-algorithms/","title":"Machine Learning Algorithms","text":"<ul> <li>Decision Tree</li> <li>Naive Bayes Classifier</li> </ul>"},{"location":"course/ml-algorithms/all/","title":"T\u1ed5ng h\u1ee3p Machine Learning Algorithms","text":""},{"location":"course/ml-algorithms/all/#linear-regression","title":"Linear Regression","text":"\\[ \\begin{array}{l} \\mathbf{x} \\in \\mathbb{R}^m, \\quad y \\in \\mathbb{R} \\\\ \\hat{y} = \\bar{\\mathbf{x}}^\\intercal \\mathbf{w}, \\quad \\mathbf{w} \\in \\mathbb{R}^{m + 1} \\end{array} \\] <p>Loss function:</p> \\[ \\begin{array}{l} J(\\mathbf{w})   &amp;=&amp; \\dfrac{1}{2N} \\displaystyle \\sum_{i=1}^N \\left( y_i - \\hat{y}_i \\right)^2 \\\\                 &amp;=&amp; \\dfrac{1}{2N} \\left[ \\left(y_1 -  \\bar{\\mathbf{x}}_1^\\intercal \\mathbf{w} \\right)^2 + \\dots + \\left(y_N - \\bar{\\mathbf{x}}_N^\\intercal \\mathbf{w} \\right)^2 \\right] \\\\                 &amp;=&amp; \\dfrac{1}{2N} \\displaystyle \\lVert \\bar{\\mathbf{X}}^\\intercal \\mathbf{w} - \\mathbf{y} \\rVert_2^2 \\end{array} \\] <p>\u0110\u1ea1o h\u00e0m:</p> \\[ \\dfrac{\\partial J}{\\partial \\mathbf{w}} = \\dfrac{1}{N} \\bar{\\mathbf{X}} \\left( \\bar{\\mathbf{X}}^\\intercal \\mathbf{w} - \\mathbf{y} \\right) \\] <p>Code</p> <pre><code>class LinearRegression:\n    def __init__(self, init_w: np.ndarray, lr: float, n_iters: int) -&gt; None:\n        self.w = init_w\n        self.lr = lr\n        self.n_iters = n_iters\n\n    def loss(self, X: np.ndarray, y: np.ndarray):\n        y_hat = X.T.dot(self.w)\n        return (np.linalg.norm(y - y_hat, 2) ** 2) / (2 * N)\n\n    def fit(self, X: np.ndarray, y: np.ndarray):\n        y = np.expand_dims(y, axis=1)\n\n        for i in range(self.n_iters):\n            grad_w = 1 / N * (X.dot(X.T.dot(self.w) - y))\n            self.w -= self.lr * grad_w\n\n    def predict(self, x: np.ndarray):\n        return x.transpose().dot(self.w)\n</code></pre>"},{"location":"course/ml-algorithms/all/#logistic-regression","title":"Logistic Regression","text":"\\[ \\begin{array}{l} \\mathbf{x} \\in \\mathbb{R}^m, \\quad y \\in \\left\\{ 0, 1 \\right\\} \\\\ \\hat{y} = \\sigma(\\bar{\\mathbf{x}}^\\intercal \\mathbf{w}), \\quad \\mathbf{w} \\in \\mathbb{R}^{m + 1} \\\\ \\sigma(z) = \\dfrac{1}{1 + e^{-z}} \\end{array} \\] <p>Gradient descent:</p> \\[ \\mathbf{w} = \\mathbf{w} - \\eta \\mathbf{X} \\left( \\hat{\\mathbf{y}} - \\mathbf{y} \\right) \\] <p>Code</p> <pre><code>class LogisticRegression:\n    def __init__(self, pretrained: np.ndarray, lr: float, n_iter: int) -&gt; None:\n        self.w = pretrained\n        self.lr = lr\n        self.n_iter = n_iter\n\n    def fit(self, X, y):\n        for _ in range(self.n_iter):\n            y_hat = sigmoid(X.T @ self.w)\n            J = X @ (y_hat - y)\n            J /= X.shape[1]\n            self.w -= self.lr * J\n\n    def predict_proba(self, X):\n        return sigmoid(X.T @ self.w)\n\n    def predict(self, X):\n        return self.predict_proba(X) &gt;= 0.5\n</code></pre>"},{"location":"course/ml-algorithms/all/#svm","title":"SVM","text":"\\[ \\begin{array}{l} \\mathbf{x} \\in \\mathbb{R}^m, \\quad y \\in \\left\\{ -1, 1 \\right\\} \\\\ \\hat{y} = \\mathbf{w}^\\intercal\\mathbf{x} + b, \\quad \\mathbf{w} \\in \\mathbb{R}^m, \\quad b \\in \\mathbb{R} \\end{array} \\] <p>Loss function:</p> \\[ J(\\mathbf{\\bar{w}}) = \\underbrace{\\sum_{i=1}^N \\max(0, 1 - y_i\\bar{\\mathbf{w}}^T\\bar{\\mathbf{x}}_i)}_{\\text{hinge loss}} + \\underbrace{\\frac{\\lambda}{2} \\lVert \\mathbf{w} \\rVert_2^2}_{\\text{regularization}} \\] <p>Gradient descent:</p> \\[ \\bar{\\mathbf{w}} = \\bar{\\mathbf{w}} - \\eta \\left(\\sum_{i \\in \\mathcal{H}} - y_i\\bar{\\mathbf{x}}_n + \\lambda \\left[\\begin{matrix} \\mathbf{w}\\newline 0 \\end{matrix}\\right]\\right), \\quad \\mathcal{H} = \\left\\{ i: y_i\\bar{\\mathbf{w}}^T\\bar{\\mathbf{x}}_i &lt; 1 \\right\\} \\] <p>Code</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_circles, make_classification\nfrom sklearn import preprocessing\n\nnp.random.seed(42)\n\nmeans = [[2, 2], [2.75, 1.25]]\ncov = [[.3, .15], [.15, .3]]\nN = 50\nX0 = np.random.multivariate_normal(means[0], cov, N)\nX1 = np.random.multivariate_normal(means[1], cov, N)\n\nX = np.concatenate((X0.T, X1.T), axis = 1)\ny = np.concatenate((np.ones((1, N)), -1*np.ones((1, N))), axis = 1)\n\n\nclass SVM:\n    def __init__(self, w: np.ndarray, lr: float, regularization: float) -&gt; None:\n        self.w = w\n        self.lr = lr\n        self.lamb = regularization\n\n    def y_hat(self, X: np.ndarray, y: np.ndarray):\n        return self.w.T @ X\n\n    def loss(self, X: np.ndarray, y: np.ndarray):\n        z = self.y_hat(X, y)  # Shape (1, N)\n        return (np.sum(np.maximum(0, 1 - y * z)) + self.lamb * 0.5 * np.linalg.norm(self.w, 2) ** 2) / X.shape[1]\n\n    def grad(self, X: np.ndarray, y: np.ndarray):\n        z = self.y_hat(X, y)  # Shape (1, N)\n        yz = y * z  # Shape (1, N)\n        active_set = np.where(yz &lt; 1)[1]\n\n        yX = -y * X  # Shape (m, N)\n\n        w_0 = self.w.copy()\n        w_0[-1] = 0\n\n        grad_w = (np.sum(yX[:, active_set], axis=1, keepdims=True) + self.lamb * w_0) / X.shape[1]  # Shape (m, 1)\n\n        return grad_w\n\n    def fit(self, X: np.ndarray, y: np.ndarray, n_iter: int = 1e6):\n        it = 0\n        best_loss = 1e9\n        best_iter = -1\n        while it &lt; n_iter:\n            it += 1\n            gw = self.grad(X, y)\n            self.w -= self.lr * gw\n\n            loss = self.loss(X, y)\n            if loss &lt; best_loss:\n                best_loss = loss\n                best_iter = it\n            elif it - best_iter &gt; 100:\n                print(\"No improve in the last 20 iter\")\n                break\n\n            if (it % 100) == 0:\n                print(f\"iter {it}; loss: {loss}\")\n</code></pre>"},{"location":"course/ml-algorithms/all/#k-nn","title":"K-NN","text":"<p>Code</p> <pre><code>class KNN:\n    def __init__(self, k: int) -&gt; None:\n        print(\"k = \", k)\n        self.k = k\n        self.X = None\n        self.y = None\n\n    def fit(self, X, y):\n        self.X = X\n        self.y = y\n\n    def predict(self, z: np.ndarray):\n        indices = list(range(X.shape[1]))\n        indices = sorted(\n            indices,\n            key=lambda i: np.linalg.norm(self.X[:, i].reshape(2, 1), 2) ** 2 - 2 * z.transpose().dot(self.X[:, i].reshape(2, 1))\n        )\n        knn_indices = indices[: self.k]\n        knn_labels = [self.y[i] for i in knn_indices]\n        return knn_indices, Counter(knn_labels).most_common(1)[0][0]\n</code></pre>"},{"location":"course/ml-algorithms/all/#k-means","title":"K-means","text":"<p>Code</p> <pre><code>class KMeansCluster:\n    def __init__(self, n_cluster: int):\n        self.n_cluster = n_cluster\n\n        self.centroids = []\n        self.cluster_of_item = []\n\n    def fit(self, X):\n        self.centroids = random.choices(X, k=self.n_cluster)\n        self.cluster_of_item = [-1] * len(X)\n\n        while True:\n            stop = True\n\n            for ix, x in enumerate(X):\n                closet_center_idx = min(list(range(len(self.centroids))), key=lambda i: np.linalg.norm(x - self.centroids[i], 2))\n                if self.cluster_of_item[ix] != closet_center_idx:\n                    stop = False\n\n                self.cluster_of_item[ix] = closet_center_idx\n\n            for ic, _ in enumerate(self.centroids):\n                x_in_cluster = [X[i] for i in range(len(X)) if self.cluster_of_item[i] == ic]\n                new_center = np.array(x_in_cluster).mean(axis=0)\n                self.centroids[ic] = new_center\n\n            if stop:\n                break\n</code></pre>"},{"location":"course/ml-algorithms/all/#navie-bayes-classifier","title":"Navie Bayes Classifier","text":"<p>Navie Bayes Classifier</p>"},{"location":"course/ml-algorithms/all/#decision-tree","title":"Decision Tree","text":"<p>Decision Tree</p>"},{"location":"course/ml-algorithms/all/#random-forest","title":"Random Forest","text":"<pre><code>class RandomForest:\n    def __init__(self, num_trees: int) -&gt; None:\n        self.num_trees = num_trees\n        self.trees = []\n\n    def bootstrap_sample(self, data):\n        n_samples = data.shape[0]\n        indices = np.random.choice(n_samples, size=n_samples, replace=True)\n        bootstrap_sample = data.iloc[indices].reset_index(drop=True)\n        return bootstrap_sample\n\n    def fit(self, data, target_column):\n        for _ in range(self.num_trees):\n            tree = DecisionTree()\n            sample_data = self.bootstrap_sample(data)\n            tree.fit(sample_data, target_column=target_column)\n            self.trees.append(tree)\n\n    def predict(self, new_data):\n        predictions = [tree.predict(new_data) for tree in self.trees]\n        labels = [list(pred) for pred in zip(*predictions)]\n        return [Counter(lb).most_common(1)[0][0] for lb in labels]\n</code></pre>"},{"location":"course/ml-algorithms/decision-tree/","title":"Decision Tree","text":"<p>B\u00e0i n\u00e0y s\u1ebd n\u00f3i v\u1ec1 thu\u1eadt to\u00e1n Decision Tree v\u00e0 th\u1ef1c h\u00e0nh n\u00f3 tr\u00ean Python.</p> <p>\u0110\u1ecdc b\u00e0i g\u1ed1c \u1edf b\u00e0i vi\u1ebft tr\u00ean forum Machine Learning c\u01a1 b\u1ea3n.</p>"},{"location":"course/ml-algorithms/decision-tree/#bai-toan","title":"B\u00e0i to\u00e1n","text":"<p>T\u1eeb m\u1ed9t b\u1ea3ng d\u1eef li\u1ec7u, ta s\u1ebd x\u00e2y d\u1ef1ng m\u1ed9t Decision Tree \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n nh\u00e3n c\u1ee7a m\u1ed9t \u0111i\u1ec3m d\u1eef li\u1ec7u m\u1edbi khi bi\u1ebft c\u00e1c thu\u1ed9c t\u00ednh c\u1ee7a \u0111i\u1ec3m d\u1eef li\u1ec7u \u0111\u00f3.</p> Th\u1ef1c h\u00e0nh <p>Cho m\u1ed9t b\u1ea3ng d\u1eef li\u1ec7u ghi ch\u00e9p l\u1ea1i d\u1eef li\u1ec7u th\u1eddi ti\u1ebft c\u1ee7a 14 ng\u00e0y, c\u00f9ng v\u1edbi \u0111\u00f3 l\u00e0 vi\u1ec7c m\u1ed9t \u0111\u1ed9i b\u00f3ng c\u00f3 quy\u1ebft \u0111\u1ecbnh \u0111i ch\u01a1i b\u00f3ng hay kh\u00f4ng:</p> B\u1ea3ng d\u1eef li\u1ec7u <code>weather.csv</code> id outlook temperature humidity wind play 1 sunny hot high weak no 2 sunny hot high strong no 3 overcast hot high weak yes 4 rainy mild high weak yes 5 rainy cool normal weak yes 6 rainy cool normal strong no 7 overcast cool normal strong yes 8 sunny mild high weak no 9 sunny cool normal weak yes 10 rainy mild normal weak yes 11 sunny mild normal strong yes 12 overcast mild high strong yes 13 overcast hot normal weak yes 14 rainy mild high strong no <p>T\u1eeb b\u1ea3ng d\u1eef li\u1ec7u n\u00e0y, ta s\u1ebd x\u00e2y d\u1ef1ng m\u1ed9t m\u00f4 h\u00ecnh Decision Tree \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n \u0111\u1ed9i b\u00f3ng n\u00e0y c\u00f3 \u0111i ch\u01a1i b\u00f3ng hay kh\u00f4ng n\u1ebfu bi\u1ebft d\u1eef li\u1ec7u th\u1eddi ti\u1ebft c\u1ee7a ng\u00e0y h\u00f4m \u0111\u00f3. N\u00f3i c\u00e1ch kh\u00e1c, ta c\u1ea7n d\u1ef1 \u0111o\u00e1n gi\u00e1 tr\u1ecb c\u1ee7a play khi bi\u1ebft gi\u00e1 tr\u1ecb c\u1ee7a 4 thu\u1ed9c t\u00ednh l\u00e0 outlook, temperature, humidity, wind.</p>"},{"location":"course/ml-algorithms/decision-tree/#xay-dung-decision-tree","title":"X\u00e2y d\u1ef1ng Decision Tree","text":"<p>\u0110\u1ea7u ti\u00ean, v\u1edbi b\u1ea3ng d\u1eef li\u1ec7u ban \u0111\u1ea7u, ta c\u1ea7n t\u00ecm m\u1ed9t thu\u1ed9c t\u00ednh \u0111\u1ec3 chia d\u1eef li\u1ec7u th\u00e0nh c\u00e1c nh\u00f3m kh\u00e1c nhau, m\u1ed7i nh\u00f3m t\u01b0\u01a1ng \u1ee9ng v\u1edbi m\u1ed9t gi\u00e1 tr\u1ecb c\u1ee7a thu\u1ed9c t\u00ednh \u0111\u00f3.</p> Th\u1ef1c h\u00e0nh <p>\u0110\u1ed1i v\u1edbi b\u00e0i to\u00e1n c\u1ee5 th\u1ec3 n\u00f3i tr\u00ean, ta c\u1ea7n t\u00ecm m\u1ed9t trong s\u1ed1 4 thu\u1ed9c t\u00ednh l\u00e0 outlook, temperature, humidity, wind \u0111\u1ec3 chia d\u1eef li\u1ec7u th\u00e0nh c\u00e1c nh\u00f3m kh\u00e1c nhau, m\u1ed7i nh\u00f3m t\u01b0\u01a1ng \u1ee9ng v\u1edbi m\u1ed9t gi\u00e1 tr\u1ecb c\u1ee7a thu\u1ed9c t\u00ednh \u0111\u00f3.</p> <p>V\u1eady trong c\u00e1c thu\u1ed9c t\u00ednh c\u1ee7a m\u1ed9t b\u1ea3ng d\u1eef li\u1ec7u, l\u00e0m sao \u0111\u1ec3 bi\u1ebft ta n\u00ean chia theo thu\u1ed9c t\u00ednh n\u00e0o?</p> <p>C\u00e2u tr\u1ea3 l\u1eddi l\u00e0 ta s\u1ebd \u0111i t\u00ednh information gain c\u1ee7a t\u1eebng thu\u1ed9c t\u00ednh, sau \u0111\u00f3 ch\u1ecdn ra thu\u1ed9c t\u00ednh c\u00f3 information gain l\u1edbn nh\u1ea5t r\u1ed3i chia theo thu\u1ed9c t\u00ednh \u0111\u00f3.</p> <p>C\u00f4ng th\u1ee9c t\u00ednh information gain c\u1ee7a m\u1ed9t thu\u1ed9c t\u00ednh \\(x\\) trong b\u1ea3ng d\u1eef li\u1ec7u \\(\\mathcal{S}\\) nh\u01b0 sau:</p> \\[ \\tag{1} G(x, \\mathcal{S}) = H(\\mathcal{S}) - H(x, \\mathcal{S}) \\] <p>trong \u0111\u00f3:</p> <ul> <li>\\(H(\\mathcal{S})\\) l\u00e0 entropy c\u1ee7a b\u1ea3ng d\u1eef li\u1ec7u \\(\\mathcal{S}\\)</li> <li>\\(H(x, \\mathcal{S})\\) l\u00e0 weighted entropy c\u1ee7a b\u1ea3ng d\u1eef li\u1ec7u \\(\\mathcal{S}\\) sau khi \u0111\u01b0\u1ee3c chia theo thu\u1ed9c t\u00ednh \\(x\\)</li> </ul> <p>V\u1eady th\u00ec 2 c\u00e1i n\u00e0y \u0111\u01b0\u1ee3c t\u00ednh nh\u01b0 th\u1ebf n\u00e0o?</p>"},{"location":"course/ml-algorithms/decision-tree/#entropy","title":"Entropy","text":"<p>Cho b\u1ea3ng d\u1eef li\u1ec7u \\(\\mathcal{S}\\), entropy c\u1ee7a n\u00f3 \u0111\u01b0\u1ee3c t\u00ednh nh\u01b0 sau:</p> \\[ \\tag{2} H(\\mathcal{S}) = - \\sum_{c \\in \\mathbf{C}} \\dfrac{N_c}{N} \\log_2 \\left( \\dfrac{N_c}{N} \\right) \\] <p>trong \u0111\u00f3:</p> <ul> <li>\\(\\mathbf{C}\\) l\u00e0 t\u1eadp c\u00e1c class c\u1ee7a b\u00e0i to\u00e1n</li> <li>\\(N_c\\) l\u00e0 s\u1ed1 \u0111i\u1ec3m d\u1eef li\u1ec7u thu\u1ed9c class \\(c\\) trong b\u1ea3ng d\u1eef li\u1ec7u \\(\\mathcal{S}\\)</li> <li>\\(N\\) l\u00e0 t\u1ed5ng s\u1ed1 \u0111i\u1ec3m d\u1eef li\u1ec7u trong b\u1ea3ng d\u1eef li\u1ec7u \\(\\mathcal{S}\\)</li> </ul> <p>L\u01b0u \u00fd</p> <ul> <li>Ph\u00e9p \\(\\log\\) l\u00e0 l\u1ea5y theo c\u01a1 s\u1ed1 \\(2\\).</li> <li>Quy \u01b0\u1edbc: \\(0 \\log 0 = 0\\)</li> </ul> Th\u1ef1c h\u00e0nh <p>V\u1edbi b\u1ea3ng d\u1eef li\u1ec7u \u0111\u00e3 cho, ta c\u00f3:</p> <ul> <li>\\(\\mathbf{C} = \\left\\{ \\texttt{yes}, \\texttt{no} \\right\\}\\)</li> <li>\\(N = 14\\)</li> <li>\\(N_{\\texttt{yes}} = 9\\); \\(N_{\\texttt{no}} = 5\\)</li> </ul> <p>Do \u0111\u00f3, ta t\u00ednh \u0111\u01b0\u1ee3c \\(H(\\mathcal{S})\\):</p> \\[ H(\\mathcal{S}) = - \\frac{5}{14}\\log\\left(\\frac{5}{14}\\right) - \\frac{9}{14}\\log\\left(\\frac{9}{14}\\right) \\approx 0.9403 \\]"},{"location":"course/ml-algorithms/decision-tree/#weighted-entropy","title":"Weighted Entropy","text":"<p>Cho b\u1ea3ng d\u1eef li\u1ec7u \\(\\mathcal{S}\\) v\u00e0 m\u1ed9t thu\u1ed9c t\u00ednh \\(x\\), weighted entropy c\u1ee7a \\(\\mathcal{S}\\) khi chia theo thu\u1ed9c t\u00ednh \\(x\\) nh\u01b0 sau:</p> \\[ \\tag{3} H(x, \\mathcal{S}) = \\sum_{k \\in K} \\frac{m_k}{N} H(\\mathcal{S}_k) \\] <p>trong \u0111\u00f3:</p> <ul> <li>\\(K\\) l\u00e0 t\u1eadp c\u00e1c gi\u00e1 tr\u1ecb c\u1ee7a thu\u1ed9c t\u00ednh \\(x\\)</li> <li>\\(N\\) l\u00e0 t\u1ed5ng s\u1ed1 \u0111i\u1ec3m d\u1eef li\u1ec7u trong b\u1ea3ng d\u1eef li\u1ec7u \\(\\mathcal{S}\\)</li> <li>\\(\\mathcal{S}_k\\) l\u00e0 b\u1ea3ng d\u1eef li\u1ec7u m\u1edbi thu \u0111\u01b0\u1ee3c khi ch\u1ec9 l\u1ea5y c\u00e1c \u0111i\u1ec3m d\u1eef li\u1ec7u c\u00f3 \\(x = k\\)</li> <li>\\(m_k\\) l\u00e0 t\u1ed5ng s\u1ed1 \u0111i\u1ec3m d\u1eef li\u1ec7u c\u00f3 \\(x = k\\). N\u00f3i c\u00e1ch kh\u00e1c, \\(m_k\\) l\u00e0 t\u1ed5ng s\u1ed1 \u0111i\u1ec3m d\u1eef li\u1ec7u c\u1ee7a \\(\\mathcal{S}_k\\)</li> </ul> Th\u1ef1c h\u00e0nh <p>V\u1edbi b\u1ea3ng d\u1eef li\u1ec7u ban \u0111\u1ea7u, x\u00e9t thu\u1ed9c t\u00ednh outlook, c\u00f3 3 gi\u00e1 tr\u1ecb l\u00e0 sunny, overcast, rainy. T\u01b0\u01a1ng \u1ee9ng ta c\u00f3 3 b\u1ea3ng d\u1eef li\u1ec7u m\u1edbi l\u00e0 \\(\\mathcal{S}_s\\), \\(\\mathcal{S}_o\\), \\(\\mathcal{S}_r\\):</p> \\(\\mathcal{S}_s\\)\\(\\mathcal{S}_o\\)\\(\\mathcal{S}_r\\) id outlook temperature humidity wind play 1 sunny hot high weak no 2 sunny hot high strong no 8 sunny mild high weak no 9 sunny cool normal weak yes 11 sunny mild normal strong yes id outlook temperature humidity wind play 3 overcast hot high weak yes 7 overcast cool normal strong yes 12 overcast mild high strong yes 13 overcast hot normal weak yes id outlook temperature humidity wind play 4 rainy mild high weak yes 5 rainy cool normal weak yes 6 rainy cool normal strong no 10 rainy mild normal weak yes 14 rainy mild high strong no <p>S\u1ed1 \u0111i\u1ec3m d\u1eef li\u1ec7u c\u1ee7a 3 b\u1ea3ng d\u1eef li\u1ec7u n\u00e0y l\u1ea7n l\u01b0\u1ee3t l\u00e0: \\(m_s = 5\\), \\(m_o = 4\\), \\(m_r = 5\\).</p> <p>Ta t\u00ednh \u0111\u01b0\u1ee3c entropy c\u1ee7a 3 b\u1ea3ng d\u1eef li\u1ec7u n\u00e0y nh\u01b0 sau:</p> \\[ \\begin{eqnarray}     H(\\mathcal{S}_s) &amp;=&amp;-\\frac{3}{5}\\log\\left(\\frac{3}{5}\\right) - \\frac{2}{5}\\log\\left(\\frac{2}{5}\\right) \\approx 0.9710 \\\\     H(\\mathcal{S}_o) &amp;=&amp;-\\frac{0}{4}\\log\\left(\\frac{0}{4}\\right) - \\frac{4}{4}\\log\\left(\\frac{4}{4}\\right) = 0\\\\     H(\\mathcal{S}_r) &amp;=&amp; -\\frac{2}{5}\\log\\left(\\frac{2}{5}\\right) - \\frac{3}{5}\\log\\left(\\frac{3}{5}\\right) \\approx 0.9710 \\end{eqnarray} \\] <p>T\u1eeb \u0111\u00f3 ta t\u00ednh \u0111\u01b0\u1ee3c weighted entropy c\u1ee7a \\(\\mathcal{S}\\) khi chia theo thu\u1ed9c t\u00ednh outlook nh\u01b0 sau:</p> \\[     H({outlook}, \\mathcal{S}) = \\frac{5}{14}H(\\mathcal{S}_s) + \\frac{4}{14}H(\\mathcal{S}_o) + \\frac{5}{14}H(\\mathcal{S}_r) \\approx 0.6935 \\] <p>T\u01b0\u01a1ng t\u1ef1, ta c\u00f3 th\u1ec3 t\u00ednh \u0111\u01b0\u1ee3c weighted entropy cho c\u00e1c thu\u1ed9c t\u00ednh c\u00f2n l\u1ea1i:</p> \\[ H({temperature, \\mathcal{S}}) \\approx 0.9111, \\quad H(humidity, \\mathcal{S}) \\approx 0.7885, \\quad H(wind, \\mathcal{S}) \\approx 0.8922 \\]"},{"location":"course/ml-algorithms/decision-tree/#information-gain","title":"Information Gain","text":"<p>Sau khi t\u00ednh \u0111\u01b0\u1ee3c entropy c\u1ee7a b\u1ea3ng d\u1eef li\u1ec7u v\u00e0 weighted entropy c\u1ee7a t\u1eebng thu\u1ed9c t\u00ednh, ta t\u00ednh information gain c\u1ee7a t\u1eebng thu\u1ed9c t\u00ednh theo c\u00f4ng th\u1ee9c \\((1)\\). Ch\u1ecdn ra thu\u1ed9c t\u00ednh c\u00f3 information gain l\u1edbn nh\u1ea5t v\u00e0 chia b\u1ea3ng d\u1eef li\u1ec7u theo thu\u1ed9c t\u00ednh \u0111\u00f3 \u0111\u1ec3 \u0111\u01b0\u1ee3c c\u00e1c b\u1ea3ng d\u1eef li\u1ec7u m\u1edbi nh\u1ecf h\u01a1n.</p> <p>D\u1ec5 th\u1ea5y thu\u1ed9c t\u00ednh c\u00f3 information gain l\u1edbn nh\u1ea5t th\u00ec ch\u00ednh l\u00e0 thu\u1ed9c t\u00ednh c\u00f3 weighted entropy nh\u1ecf nh\u1ea5t.</p> <p>\u1ede \u0111\u00e2y b\u1ea3ng d\u1eef li\u1ec7u ban \u0111\u1ea7u t\u01b0\u01a1ng \u1ee9ng v\u1edbi m\u1ed9t node c\u1ee7a Decision Tree, c\u00e1c b\u1ea3ng d\u1eef li\u1ec7u con t\u01b0\u01a1ng \u1ee9ng v\u1edbi c\u00e1c node con c\u1ee7a node \u0111\u00f3.</p> <p>V\u1edbi m\u1ed7i b\u1ea3ng d\u1eef li\u1ec7u t\u01b0\u01a1ng \u1ee9ng v\u1edbi c\u00e1c node con, ta ti\u1ebfp t\u1ee5c khi n\u00f3 th\u00e0nh c\u00e1c d\u1eef li\u1ec7u nh\u1ecf h\u01a1n cho \u0111\u1ebfn khi b\u1ea3ng d\u1eef li\u1ec7u thu \u0111\u01b0\u1ee3c ch\u1ec9 c\u00f3 \u0111\u00fang 1 class (node l\u00e1), hay b\u1ea3ng d\u1eef li\u1ec7u thu \u0111\u01b0\u1ee3c c\u00f3 entropy b\u1eb1ng \\(0\\)</p> Th\u1ef1c h\u00e0nh <p>V\u1edbi b\u1ea3ng d\u1eef li\u1ec7u ban \u0111\u1ea7u, ta th\u1ea5y outlook l\u00e0 thu\u1ed9c t\u00ednh c\u00f3 weighted entropy nh\u1ecf nh\u1ea5t, nh\u01b0 v\u1eady ta s\u1ebd ch\u1ecdn thu\u1ed9c t\u00ednh n\u00e0y \u0111\u1ea7u ti\u00ean cho Decision Tree.</p> <p>B\u1eaft \u0111\u1ea7u v\u1edbi b\u1ea3ng d\u1eef li\u1ec7u ban \u0111\u1ea7u t\u01b0\u01a1ng \u1ee9ng v\u1edbi root node, ta \u0111\u01b0\u1ee3c 3 b\u1ea3ng d\u1eef li\u1ec7u con t\u01b0\u01a1ng \u1ee9ng v\u1edbi 3 node con.</p> <p>Ti\u1ebfp t\u1ee5c th\u1ef1c hi\u1ec7n c\u00e1c b\u01b0\u1edbc tr\u00ean \u1edf c\u00e1c b\u1ea3ng d\u1eef li\u1ec7u con cho \u0111\u1ebfn khi thu \u0111\u01b0\u1ee3c b\u1ea3ng d\u1eef li\u1ec7u c\u00f3 entropy b\u1eb1ng 0, ta \u0111\u01b0\u1ee3c h\u00ecnh d\u1ea1ng c\u1ee7a Decision Tree cho b\u00e0i to\u00e1n n\u00e0y nh\u01b0 sau<sup>1</sup>:</p> <p> </p>"},{"location":"course/ml-algorithms/decision-tree/#ieu-kien-dung","title":"\u0110i\u1ec1u ki\u1ec7n d\u1eebng","text":"<p>Trong thu\u1eadt to\u00e1n tr\u00ean, ta li\u00ean t\u1ee5c chia c\u00e1c node cho \u0111\u1ebfn khi \u0111\u01b0\u1ee3c node l\u00e1. K\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng s\u1ebd thu \u0111\u01b0\u1ee3c m\u1ed9t tree m\u00e0 m\u1ecdi \u0111i\u1ec3m trong t\u1eadp train \u0111\u1ec1u \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n \u0111\u00fang. L\u00fac n\u00e0y tree s\u1ebd r\u1ea5t ph\u1ee9c t\u1ea1p, nhi\u1ec1u node l\u00e1 ch\u1ec9 c\u00f3 m\u1ed9t v\u00e0i \u0111i\u1ec3m d\u1eef li\u1ec7u. Nh\u01b0 v\u1eady, t\u00ecnh tr\u1ea1ng overfitting r\u1ea5t d\u1ec5 x\u1ea3y ra.</p> <p>\u0110\u1ec3 tr\u00e1nh t\u00ecnh tr\u1ea1ng tr\u00ean, c\u00f3 m\u1ed9t s\u1ed1 ph\u01b0\u01a1ng ph\u00e1p \u0111\u1ec3 ki\u1ec3m tra \u0111i\u1ec1u ki\u1ec7n d\u1eebng. N\u1ebfu m\u1ed9t trong s\u1ed1 c\u00e1c \u0111i\u1ec1u ki\u1ec7n n\u00e0y x\u1ea3y ra, ta s\u1ebd kh\u00f4ng ti\u1ebfp t\u1ee5c ph\u00e2n chia node \u0111\u00f3 v\u00e0 coi n\u00f3 l\u00e0 m\u1ed9t node l\u00e1:</p> <ul> <li>N\u1ebfu node \u0111\u00f3 c\u00f3 entropy b\u1eb1ng 0, t\u1ee9c m\u1ecdi \u0111i\u1ec3m trong node \u0111\u1ec1u thu\u1ed9c m\u1ed9t class</li> <li>N\u1ebfu node \u0111\u00f3 c\u00f3 s\u1ed1 ph\u1ea7n t\u1eed nh\u1ecf h\u01a1n m\u1ed9t ng\u01b0\u1ee1ng n\u00e0o \u0111\u00f3</li> <li>N\u1ebfu kho\u1ea3ng c\u00e1ch t\u1eeb node \u0111\u00f3 \u0111\u1ebfn root node \u0111\u1ea1t t\u1edbi m\u1ed9t gi\u00e1 tr\u1ecb n\u00e0o \u0111\u00f3</li> <li>N\u1ebfu t\u1ed5ng s\u1ed1 node l\u00e1 v\u01b0\u1ee3t qua m\u1ed9t ng\u01b0\u1ee1ng n\u00e0o \u0111\u00f3</li> <li>N\u1ebfu vi\u1ec7c ph\u00e2n chia node \u0111\u00f3 kh\u00f4ng l\u00e0m gi\u1ea3m entropy qu\u00e1 nhi\u1ec1u (information gain nh\u1ecf h\u01a1n m\u1ed9t ng\u01b0\u1ee1ng n\u00e0o \u0111\u00f3)</li> </ul> <p>Khi s\u1eed d\u1ee5ng c\u00e1c ph\u01b0\u01a1ng ph\u00e1p tr\u00ean, ta ch\u1ea5p nh\u1eadn vi\u1ec7c c\u00f3 m\u1ed9t s\u1ed1 \u0111i\u1ec3m trong t\u1eadp train b\u1ecb ph\u00e2n l\u1edbp sai \u0111\u1ec3 tr\u00e1nh overfitting.</p> <p>Ngo\u00e0i c\u00e1c ph\u01b0\u01a1ng ph\u00e1p tr\u00ean, m\u1ed9t ph\u01b0\u01a1ng ph\u00e1p ph\u1ed5 bi\u1ebfn kh\u00e1c \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 tr\u00e1nh overfitting l\u00e0 pruning.</p>"},{"location":"course/ml-algorithms/decision-tree/#pruning","title":"Pruning","text":"<p>Note</p> <p>Ph\u1ea7n n\u00e0y ch\u1ec9 tr\u00ecnh b\u00e0y \u00fd t\u01b0\u1edfng c\u1ee7a ph\u01b0\u01a1ng ph\u00e1p pruning ch\u1ee9 kh\u00f4ng \u0111i v\u00e0o chi ti\u1ebft.</p> <p>\u00dd t\u01b0\u1edfng chung c\u1ee7a ph\u01b0\u01a1ng ph\u00e1p pruning l\u00e0 \u0111\u1ea7u ti\u00ean, x\u00e2y d\u1ef1ng m\u1ed9t decision tree trong \u0111\u00f3 m\u1ecdi \u0111i\u1ec3m trong t\u1eadp train \u0111\u1ec1u \u0111\u01b0\u1ee3c ph\u00e2n l\u1edbp \u0111\u00fang. Sau \u0111\u00f3, c\u00e1c node l\u00e1 c\u00f3 chung m\u1ed9t node cha s\u1ebd \u0111\u01b0\u1ee3c c\u1eaft t\u1ec9a v\u00e0 node cha \u0111\u00f3 s\u1ebd tr\u1edf th\u00e0nh m\u1ed9t node l\u00e1.</p> <p>M\u1ed9t s\u1ed1 c\u00e1ch \u0111\u1ec3 pruning nh\u01b0 sau:</p> <ol> <li> <p>Tr\u01b0\u1edbc ti\u00ean dataset \u0111\u01b0\u1ee3c chia th\u00e0nh m\u1ed9t t\u1eadp train v\u00e0 t\u1eadp validation. Decision tree \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng tr\u00ean t\u1eadp train cho t\u1edbi khi m\u1ecdi \u0111i\u1ec3m trong t\u1eadp train \u0111\u1ec1u \u0111\u01b0\u1ee3c ph\u00e2n l\u1edbp \u0111\u00fang. Sau \u0111\u00f3 \u0111i ng\u01b0\u1ee3c t\u1eeb c\u00e1c node l\u00e1, c\u1eaft t\u1ec9a c\u00e1c node anh em c\u1ee7a n\u00f3 (c\u00e1c node c\u00f3 c\u00f9ng node cha) n\u1ebfu nh\u01b0 \u0111\u1ed9 ch\u00ednh x\u00e1c tr\u00ean t\u1eadp validation \u0111\u01b0\u1ee3c c\u1ea3i thi\u1ec7n. Khi n\u00e0o \u0111\u1ed9 ch\u00ednh x\u00e1c tr\u00ean t\u1eadp validation kh\u00f4ng c\u1ea3i thi\u1ec7n \u0111\u01b0\u1ee3c n\u1eefa th\u00ec d\u1eebng l\u1ea1i.</p> </li> <li> <p>S\u1eed d\u1ee5ng to\u00e0n b\u1ed9 t\u1eadp train \u0111\u1ec3 x\u00e2y d\u1ef1ng decision tree. Gi\u1ea3 s\u1eed decision tree cu\u1ed1i c\u00f9ng c\u00f3 \\(K\\) node l\u00e1, t\u1eadp h\u1ee3p c\u00e1c \u0111i\u1ec3m d\u1eef li\u1ec7u \u1edf m\u1ed7i node l\u00e1 l\u1ea7n l\u01b0\u1ee3t l\u00e0 \\(\\mathcal{S}_1, \\dots, \\mathcal{S}_K\\), ta \u0111\u1ecbnh ngh\u0129a h\u00e0m loss sau:</p> \\[     \\tag{4}     \\mathcal{L} = \\sum_{k = 1}^K \\frac{|\\mathcal{S}_k|}{|\\mathcal{S}|} H(\\mathcal{S}_k) + \\lambda K, \\quad \\lambda \\in \\mathbb{R}^+ \\] <p>\u0110\u00e2y ch\u00ednh l\u00e0 k\u1ef9 thu\u1eadt regularization. Gi\u00e1 tr\u1ecb c\u1ee7a h\u00e0m s\u1ed1 n\u00e0y nh\u1ecf n\u1ebfu c\u1ea3 data loss (s\u1ed1 h\u1ea1ng th\u1ee9 nh\u1ea5t) nh\u1ecf (entropy t\u1ea1i m\u1ed7i node l\u00e0 th\u1ea5p) v\u00e0 regularization (s\u1ed1 h\u1ea1ng th\u1ee9 hai) c\u0169ng nh\u1ecf (s\u1ed1 node l\u00e1 \u00edt). Tr\u01b0\u1edbc h\u1ebft, x\u00e2y d\u1ef1ng m\u1ed9t decision tree m\u00e0 m\u1ecdi \u0111i\u1ec3m trong t\u1eadp train \u0111\u1ec1u \u0111\u01b0\u1ee3c ph\u00e2n lo\u1ea1i \u0111\u00fang (to\u00e0n b\u1ed9 c\u00e1c entopy c\u1ee7a c\u00e1c node b\u1eb1ng 0). L\u00fac n\u00e0y data loss b\u1eb1ng \\(0\\) nh\u01b0ng regularization c\u00f3 th\u1ec3 l\u1edbn, khi\u1ebfn cho \\(\\mathcal{L}\\) l\u1edbn. Sau \u0111\u00f3, ta t\u1ec9a d\u1ea7n c\u00e1c node l\u00e1 sao cho \\(\\mathcal{L}\\) gi\u1ea3m. Vi\u1ec7c c\u1eaft t\u1ec9a \u0111\u01b0\u1ee3c l\u1eb7p l\u1ea1i \u0111\u1ebfn khi \\(\\mathcal{L}\\) kh\u00f4ng th\u1ec3 gi\u1ea3m \u0111\u01b0\u1ee3c n\u1eefa.</p> </li> </ol>"},{"location":"course/ml-algorithms/decision-tree/#code","title":"Code","text":"<p>Download d\u1eef li\u1ec7u <code>weather.csv</code> t\u1ea1i \u0111\u00e2y.</p> <p>\u0110\u1ea7u ti\u00ean ta import c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft:</p> <pre><code>import pandas as pd\nimport numpy as np\n</code></pre> <p>Load d\u1eef li\u1ec7u:</p> <pre><code>df = pd.read_csv(\"weather.csv\")\nprint(df)\n</code></pre> <pre><code>    id   outlook temperature humidity    wind play\n0    1     sunny         hot     high    weak   no\n1    2     sunny         hot     high  strong   no\n2    3  overcast         hot     high    weak  yes\n3    4     rainy        mild     high    weak  yes\n4    5     rainy        cool   normal    weak  yes\n5    6     rainy        cool   normal  strong   no\n6    7  overcast        cool   normal  strong  yes\n7    8     sunny        mild     high    weak   no\n8    9     sunny        cool   normal    weak  yes\n9   10     rainy        mild   normal    weak  yes\n10  11     sunny        mild   normal  strong  yes\n11  12  overcast        mild     high  strong  yes\n12  13  overcast         hot   normal    weak  yes\n13  14     rainy        mild     high  strong   no\n</code></pre> <p>Vi\u1ebft h\u00e0m t\u00ednh entropy c\u1ee7a m\u1ed9t b\u1ea3ng d\u1eef li\u1ec7u: (1)</p> <ol> <li>Nh\u1eafc l\u1ea1i: $$ \\tag{2}     H(\\mathcal{S}) = - \\sum_{c \\in \\mathbf{C}} \\dfrac{N_c}{N} \\log_2 \\left( \\dfrac{N_c}{N} \\right)     $$</li> </ol> <pre><code>def entropy(data: pd.DataFrame):\n    y = data.iloc[:, -1]  # Retrieve the labels\n    value_counts = y.value_counts()  # Calculate all N_c\n    probs = value_counts / len(y)  # Calculate all N_c / N\n    entropy = -np.sum(probs * np.log2(probs))  # Calculate the entropy\n    return entropy\n</code></pre> <p>Vi\u1ebft h\u00e0m t\u00ednh weighted entropy c\u1ee7a m\u1ed9t b\u1ea3ng d\u1eef li\u1ec7u v\u00e0 m\u1ed9t thu\u1ed9c t\u00ednh: (1)</p> <ol> <li>Nh\u1eafc l\u1ea1i: $$ \\tag{3}     H(x, \\mathcal{S}) = \\sum_{k \\in K} \\frac{m_k}{N} H(\\mathcal{S}_k)     $$</li> </ol> <pre><code>def weighted_entropy(data: pd.DataFrame, prop: str):\n    N = len(data)\n    weighted_entropy = 0\n\n    for value in data[prop].unique():\n        subset = data[data[prop] == value]  # Calculate m_k\n        value_entropy = entropy(subset)  # Calculate H(S_k)\n\n        weighted_entropy += value_entropy * len(subset) / N  # Add to the final result\n\n    return weighted_entropy\n</code></pre> <p>Ta c\u00f3 th\u1ec3 th\u1eed ch\u1ea1y h\u00e0m <code>weighted_entropy</code> tr\u00ean b\u1ea3ng d\u1eef li\u1ec7u ban \u0111\u1ea7u xem k\u1ebft qu\u1ea3 \u0111\u00e3 \u0111\u00fang ch\u01b0a:</p> <p><pre><code>for col in [\"outlook\", \"temperature\", \"humidity\", \"wind\"]:\n    print(col, weighted_entropy(df, col))\n</code></pre> <pre><code>outlook 0.6935361388961919\ntemperature 0.9110633930116763\nhumidity 0.7884504573082896\nwind 0.8921589282623617\n</code></pre> Ta th\u1ea5y n\u00f3 kh\u1edbp v\u1edbi k\u1ebft qu\u1ea3 ta \u0111\u00e3 t\u00ednh ph\u00eda tr\u00ean. Nh\u01b0 v\u1eady c\u00f3 v\u1ebb h\u00e0m <code>entropy</code> v\u00e0 <code>weighted_entropy</code> \u0111\u00e3 \u1ed5n.</p> <p>Gi\u1edd ta s\u1ebd tri\u1ec3n khai decision tree. \u0110\u1ea7u ti\u00ean, ta vi\u1ebft class <code>TreeNode</code> nh\u01b0 sau: <pre><code>class TreeNode:\n    def __init__(self, row_indices: List[int]) -&gt; None:\n        self.row_indices = row_indices  # Indices of data points of the node \n        self.split_column = None  # Property to split the data\n        self.children = {}  # A dictionary of &lt;column value&gt; : &lt;child node&gt;\n        self.label = None\n\n    def add(self, child_node, column_value):\n        self.children[column_value] = child_node\n\n    def __str__(self) -&gt; str:\n        return str(self.row_indices)\n</code></pre> V\u00e0 class <code>DecisionTree</code>: <pre><code>class DecisionTree:\n    def __init__(self) -&gt; None:\n        self.root = None  # to store the root TreeNode\n        self.leaves = []  # to store leaf nodes\n</code></pre></p> <p>V\u1edbi h\u00e0m training cho Decision Tree, ta s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n BFS \u0111\u1ec3 duy\u1ec7t c\u00e2y (code h\u01a1i d\u00e0i nh\u01b0ng c\u00f3 coment \u0111\u1ea7y \u0111\u1ee7) <pre><code>    def fit(self, data):\n        # Initialize the root node with all row indices from the dataset\n        self.root = TreeNode(list(range(len(data))))\n\n        # Exclude the label column from the features\n        X = data.iloc[:, :-1]\n\n        # Initialize the queue for BFS\n        queue = deque([self.root])\n\n        # Perform BFS to build the decision tree\n        while queue:\n            # Retrieve the current node from the queue\n            node = queue.popleft()\n\n            # Get the subset of data corresponding to the current node\n            node_data = data.iloc[node.row_indices]\n\n            # Check if the current node is a leaf node\n            if entropy(node_data) &lt; 1e-6:\n                node.label = node_data.iloc[:, -1].mode()[0]  # Assign the most frequent label to the leaf node\n                self.leaves.append(node)  # Add the leaf node to the list of leaves\n                continue  # Stop further splitting for this node\n\n            # Find the feature with the minimum entropy for splitting\n            node.split_column = min(X.columns, key=lambda col: weighted_entropy(node_data, col))\n\n            # Group the data indices by the selected split column.\n            # Note: 'splits' contains indices relative to 'node_data', not the original data.\n            splits = node_data.groupby(node_data[node.split_column]).indices\n\n            # Convert grouped indices back to the original data indices\n            for val in splits:\n                splits[val] = [node.row_indices[ind] for ind in splits[val]]\n\n            # Create child nodes for each group and add them to the current node\n            for value in splits:\n                indices = splits[value]\n                child_node = TreeNode(indices)\n                node.add(child_node, value)\n                queue.append(child_node)  # Add the child node to the queue for further processing\n</code></pre> Cu\u1ed1i c\u00f9ng l\u00e0 h\u00e0m predict. V\u1edbi m\u1ed9t b\u1ea3ng d\u1eef li\u1ec7u m\u1edbi, ta s\u1ebd duy\u1ec7t t\u1eebng h\u00e0ng c\u1ee7a b\u1ea3ng d\u1eef li\u1ec7u, \u0111\u01b0a v\u00e0o decision tree v\u1eeba x\u00e2y d\u1ef1ng \u0111\u1ec3 predict cho t\u1eebng h\u00e0ng. <pre><code>    def predict(self, new_data):\n        npoints = new_data.count()[0]  # Retrieve the number of data points in new_data\n        labels = [None] * npoints  # Initialize the list to store prediction results\n\n        for n in range(npoints):\n            x = new_data.iloc[n, :]  # Get the current data point\n            node = self.root  # Start prediction from the root node\n\n            # Traverse the tree until a leaf node is reached\n            while node.children:\n                col_to_split = node.split_column  # Get the column used for splitting at this node\n                if x[col_to_split] not in node.children:  # Check if the split value exists in the children of the current node\n                    break  # If the value is not found, this data point cannot be classified\n\n                # Move to the corresponding child node based on the split value\n                node = node.children[x[col_to_split]]\n\n            # Assign the label of the reached leaf node to the current data point\n            labels[n] = node.label\n\n        return labels\n</code></pre> Nh\u01b0 v\u1eady l\u00e0 ta \u0111\u00e3 code xong decision tree. Gi\u1edd ta s\u1ebd ch\u1ea1y th\u1eed tr\u00ean ch\u00ednh t\u1eadp d\u1eef li\u1ec7u \u0111\u00e3 cho \u0111\u1ec3 xem t\u1ea5t c\u1ea3 c\u00e1c \u0111i\u1ec3m d\u1eef li\u1ec7u \u0111\u00e3 \u0111\u01b0\u1ee3c ph\u00e2n lo\u1ea1i \u0111\u00fang hay ch\u01b0a. <pre><code>if __name__ == \"__main__\":\n    df = pd.read_csv(\"weather.csv\")\n    X = df.iloc[:, 1:]\n    y = df.iloc[:, -1]\n\n    dt = DecisionTree()\n    dt.fit(X)\n\n    print(dt.predict(X))\n    print(y.to_list())\n</code></pre> <pre><code>['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n</code></pre> K\u1ebft qu\u1ea3 ph\u00e2n lo\u1ea1i c\u1ee7a decision tree tr\u00f9ng kh\u1edbp ho\u00e0n to\u00e0n v\u1edbi label ban \u0111\u1ea7u c\u1ee7a data, nh\u01b0 v\u1eady l\u00e0 ta \u0111\u00e3 c\u00e0i \u0111\u1eb7t th\u00e0nh c\u00f4ng decision tree.</p> <p>Ta c\u00f3 th\u1ec3 v\u1ebd l\u1ea1i decision tree ta v\u1eeba x\u00e2y d\u1ef1ng nh\u01b0 sau: <pre><code>flowchart TD\n    root(\n        row_indices = 0, 1, ..., 13\n        split_column = outlook\n    )\n\n    child1(\n        row_indices = 0, 1, 7, 8, 10\n        split_column = humidity\n    )\n\n    child2(\n        row_indices = 3, 4, 5, 9, 13\n        split_column = wind\n    )\n\n    leaf1((N))\n    leaf2((Y))\n    leaf3((Y))\n    leaf4((Y))\n    leaf5((N))\n\n    root -- sunny ---&gt; child1\n    root -- overcast --&gt; leaf3\n    root -- rainy ---&gt; child2\n\n    child1 -- high --&gt; leaf1\n    child1 -- normal --&gt; leaf2\n\n    child2 -- weak --&gt; leaf4\n    child2 -- strong --&gt; leaf5\n\n    style leaf1 fill:#f3b7b6,stroke:#555,stroke-width:1px,color:#000\n    style leaf2 fill:#c4fdbb,stroke:#555,stroke-width:1px,color:#000\n    style leaf3 fill:#c4fdbb,stroke:#555,stroke-width:1px,color:#000\n    style leaf4 fill:#c4fdbb,stroke:#555,stroke-width:1px,color:#000\n    style leaf5 fill:#f3b7b6,stroke:#555,stroke-width:1px,color:#000</code></pre></p> Code ho\u00e0n ch\u1ec9nh <code>decision_tree.py</code> decision_tree.py<pre><code>from typing import List\nimport pandas as pd\nimport numpy as np\nfrom collections import deque\n\n\ndef entropy(data: pd.DataFrame):\n    y = data.iloc[:, -1]  # Retrieve the labels\n    value_counts = y.value_counts()  # Calculate all N_c\n    probs = value_counts / len(y)  # Calculate all N_c / N\n    entropy = -np.sum(probs * np.log2(probs))  # Calculate the entropy\n    return entropy\n\n\ndef weighted_entropy(data: pd.DataFrame, prop: str):\n    N = len(data)\n    weighted_entropy = 0\n\n    for value in data[prop].unique():\n        subset = data[data[prop] == value]  # Calculate m_k\n        value_entropy = entropy(subset)  # Calculate H(S_k)\n\n        weighted_entropy += value_entropy * len(subset) / N  # Add to the final result\n\n    return weighted_entropy\n\n\nclass TreeNode:\n    def __init__(self, row_indices) -&gt; None:\n        self.row_indices = row_indices\n        self.split_column = None\n        self.children = {}\n        self.label = None\n\n    def add(self, child_node, column_value):\n        self.children[column_value] = child_node\n\n    def __str__(self) -&gt; str:\n        return str(self.row_indices)\n\n\nclass DecisionTree:\n    def __init__(self) -&gt; None:\n        self.root = None  # The root node of the decision tree\n        self.leaves = []  # List to store all the leaf nodes\n\n    def fit(self, data):\n        # Initialize the root node with all row indices from the dataset\n        self.root = TreeNode(list(range(len(data))))\n\n        # Exclude the label column from the features\n        X = data.iloc[:, :-1]\n\n        # Initialize the queue for BFS\n        queue = deque([self.root])\n\n        # Perform BFS to build the decision tree\n        while queue:\n            # Retrieve the current node from the queue\n            node = queue.popleft()\n\n            # Get the subset of data corresponding to the current node\n            node_data = data.iloc[node.row_indices]\n\n            # Check if the current node is a leaf node\n            if entropy(node_data) &lt; 1e-6:\n                node.label = node_data.iloc[:, -1].mode()[0]  # Assign the most frequent label to the leaf node\n                self.leaves.append(node)  # Add the leaf node to the list of leaves\n                continue  # Stop further splitting for this node\n\n            # Find the feature with the minimum entropy for splitting\n            node.split_column = min(X.columns, key=lambda col: weighted_entropy(node_data, col))\n\n            # Group the data indices by the selected split column.\n            # Note: 'splits' contains indices relative to 'node_data', not the original data.\n            splits = node_data.groupby(node_data[node.split_column]).indices\n\n            # Convert grouped indices back to the original data indices\n            for val in splits:\n                splits[val] = [node.row_indices[ind] for ind in splits[val]]\n\n            # Create child nodes for each group and add them to the current node\n            for value in splits:\n                indices = splits[value]\n                child_node = TreeNode(indices)\n                node.add(child_node, value)\n                queue.append(child_node)  # Add the child node to the queue for further processing\n\n    def predict(self, new_data):\n        npoints = new_data.count()[0]  # Retrieve the number of data points in new_data\n        labels = [None] * npoints  # Initialize the list to store prediction results\n\n        for n in range(npoints):\n            x = new_data.iloc[n, :]  # Get the current data point\n            node = self.root  # Start prediction from the root node\n\n            # Traverse the tree until a leaf node is reached\n            while node.children:\n                col_to_split = node.split_column  # Get the column used for splitting at this node\n                if x[col_to_split] not in node.children:  # Check if the split value exists in the children of the current node\n                    break  # If the value is not found, this data point cannot be classified\n\n                # Move to the corresponding child node based on the split value\n                node = node.children[x[col_to_split]]\n\n            # Assign the label of the reached leaf node to the current data point\n            labels[n] = node.label\n\n        return labels\n\n\nif __name__ == \"__main__\":\n    df = pd.read_csv(\"weather.csv\")\n    X = df.iloc[:, 1:]\n    y = df.iloc[:, -1]\n\n    dt = DecisionTree()\n    dt.fit(X)\n\n    print(dt.predict(X))\n    print(y.to_list())\n</code></pre> <ol> <li> <p>https://machinelearningcoban.com/2018/01/14/id3/\u00a0\u21a9</p> </li> </ol>"},{"location":"course/ml-algorithms/linear-regression/","title":"Linear Regression","text":"<p>V\u00ec c\u00e1i n\u00e0y \u0111\u01a1n gi\u1ea3n n\u00ean s\u1ebd \u0111i th\u1eb3ng lu\u00f4n v\u00e0o ph\u1ea7n th\u1ef1c h\u00e0nh, v\u1eeba th\u1ef1c h\u00e0nh v\u1eeba gi\u1ea3i th\u00edch.</p>"},{"location":"course/ml-algorithms/linear-regression/#bai-toan","title":"B\u00e0i to\u00e1n","text":"<p>B\u00e0i to\u00e1n kinh \u0111i\u1ec3n l\u00e0 d\u1ef1 \u0111o\u00e1n gi\u00e1 nh\u00e0. Download data t\u1ea1i \u0111\u00e2y:</p> <p>House Sales in King County, USA</p>"},{"location":"course/ml-algorithms/linear-regression/#code","title":"Code","text":""},{"location":"course/ml-algorithms/nbc/","title":"Naive Bayes Classifier","text":"<p>B\u00e0i n\u00e0y s\u1ebd n\u00f3i v\u1ec1 thu\u1eadt to\u00e1n Decision Tree v\u00e0 th\u1ef1c h\u00e0nh n\u00f3 tr\u00ean Python.</p> <p>\u0110\u1ecdc b\u00e0i g\u1ed1c \u1edf b\u00e0i vi\u1ebft tr\u00ean forum Machine Learning c\u01a1 b\u1ea3n.</p>"},{"location":"course/ml-algorithms/nbc/#bai-toan","title":"B\u00e0i to\u00e1n","text":"<p>X\u00e9t b\u00e0i to\u00e1n classification v\u1edbi \\(C\\) classes \\(1, 2, \\dots, C\\). Gi\u1ea3 s\u1eed c\u00f3 m\u1ed9t \u0111i\u1ec3m d\u1eef li\u1ec7u \\(\\mathbf{x} \\in \\mathbb{R}^d\\), h\u00e3y t\u00ednh x\u00e1c su\u1ea5t \u0111\u1ec3 \u0111i\u1ec3m d\u1eef li\u1ec7u n\u00e0y r\u01a1i v\u00e0o class \\(c\\):</p> \\[ \\tag{1} p(c|\\mathbf{x}) \\] <p>\u0110\u1ec3 ph\u00e2n l\u1edbp m\u1ed9t \u0111i\u1ec3m d\u1eef li\u1ec7u, ta t\u00ednh x\u00e1c su\u1ea5t \u0111\u1ec3 \u0111i\u1ec3m d\u1eef li\u1ec7u \u0111\u00f3 r\u01a1i v\u00e0o m\u1ed7i class v\u00e0 ch\u1ecdn ra class c\u00f3 x\u00e1c su\u1ea5t cao nh\u1ea5t.</p> \\[ \\tag{2} c = \\arg\\max_{c \\in \\{1, \\dots, C\\}} p(c | \\mathbf{x}) \\] <p>\u00c1p d\u1ee5ng quy t\u1eafc Bayes:</p> \\[ \\tag{3} c = \\arg\\max_c p(c | \\mathbf{x}) = \\arg\\max_c \\dfrac{p(\\mathbf{x} | c) p(c)}{p(\\mathbf{x})} \\] <p>Do m\u1eabu s\u1ed1 \\(p(\\mathbf{x})\\) kh\u00f4ng ph\u1ee5 thu\u1ed9c v\u00e0o \\(c\\):</p> \\[ \\tag{4} c = \\arg\\max_c p(\\mathbf{x} | c) p(c) \\] <p>trong \u0111\u00f3:</p> <ul> <li>\\(p(c)\\): x\u00e1c su\u1ea5t \u0111\u1ec3 m\u1ed9t \u0111i\u1ec3m r\u01a1i v\u00e0o class \\(c\\)</li> <li>\\(p(\\mathbf{x} | c)\\): ph\u00e2n ph\u1ed1i c\u1ee7a \u0111i\u1ec3m d\u1eef li\u1ec7u \\(\\mathbf{x}\\) trong class \\(c\\)</li> </ul> <p>\u0110\u1ec3 d\u1ec5 t\u00ednh \\(p(\\mathbf{x} | c)\\), ta th\u01b0\u1eddng gi\u1ea3 thi\u1ebft r\u1eb1ng c\u00e1c th\u00e0nh ph\u1ea7n c\u1ee7a \\(\\mathbb{x}\\) l\u00e0 \u0111\u1ed9c l\u1eadp v\u1edbi nhau:</p> \\[ \\tag{5} p(\\mathbf{x} | c) = p(x_1, x_2, \\dots, x_d | c) =  \\prod_{i = 1}^d p(x_i | c) \\] <p>Note</p> <p>Gi\u1ea3 thi\u1ebft c\u00e1c chi\u1ec1u c\u1ee7a d\u1eef li\u1ec7u \u0111\u1ed9c l\u1eadp v\u1edbi nhau, n\u1ebfu bi\u1ebft \\(c\\), l\u00e0 qu\u00e1 ch\u1eb7t v\u00e0 \u00edt khi t\u00ecm \u0111\u01b0\u1ee3c d\u1eef li\u1ec7u m\u00e0 c\u00e1c th\u00e0nh ph\u1ea7n ho\u00e0n to\u00e0n \u0111\u1ed9c l\u1eadp v\u1edbi nhau. Tuy nhi\u00ean, gi\u1ea3 thi\u1ebft ng\u00e2y ng\u00f4 n\u00e0y l\u1ea1i mang l\u1ea1i nh\u1eefng k\u1ebft qu\u1ea3 t\u1ed1t b\u1ea5t ng\u1edd. Gi\u1ea3 thi\u1ebft v\u1ec1 s\u1ef1 \u0111\u1ed9c l\u1eadp c\u1ee7a c\u00e1c chi\u1ec1u d\u1eef li\u1ec7u n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 Naive Bayes. C\u00e1ch x\u00e1c \u0111\u1ecbnh class c\u1ee7a d\u1eef li\u1ec7u d\u1ef1a tr\u00ean gi\u1ea3 thi\u1ebft n\u00e0y c\u00f3 t\u00ean l\u00e0 Naive Bayes Classifier (NBC).<sup>1</sup></p> <p>V\u1edbi m\u1ed9t \u0111i\u1ec3m d\u1eef li\u1ec7u m\u1edbi \\(\\mathbf{x}\\), class c\u1ee7a n\u00f3 s\u1ebd \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi:</p> \\[ \\tag{6} c = \\arg\\max_{c \\in \\{1, \\dots, C\\}} p(c) \\prod_{i=1}^d p(x_i | c) \\] <p>Khi \\(d\\) l\u1edbn v\u00e0 c\u00e1c x\u00e1c su\u1ea5t \\(p(x_i | c)\\) nh\u1ecf, v\u1ebf ph\u1ea3i c\u1ee7a \\((6)\\) s\u1ebd l\u00e0 m\u1ed9t s\u1ed1 r\u1ea5t nh\u1ecf, khi t\u00ednh to\u00e1n c\u00f3 th\u1ec3 g\u1eb7p sai s\u1ed1. \u0110\u1ec3 kh\u1eafc ph\u1ee5c, ta l\u1ea5y \\(\\log\\) v\u1ebf ph\u1ea3i c\u1ee7a \\((6)\\). Vi\u1ec7c n\u00e0y kh\u00f4ng \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn k\u1ebft qu\u1ea3 v\u00ec \\(\\log\\) l\u00e0 m\u1ed9t h\u00e0m \u0111\u1ed3ng bi\u1ebfn tr\u00ean t\u1eadp c\u00e1c s\u1ed1 d\u01b0\u01a1ng.</p> \\[ \\tag{7} c = \\arg\\max_{c \\in \\{1, \\dots, C\\}} \\left( \\log(p(c)) + \\sum_{i=1}^d \\log(p(x_i | c)) \\right) \\]"},{"location":"course/ml-algorithms/nbc/#cac-phan-phoi-thuong-dung-cho-px_i-c","title":"C\u00e1c ph\u00e2n ph\u1ed1i th\u01b0\u1eddng d\u00f9ng cho \\(p(x_i | c)\\)","text":"<p>L\u01b0u \u00fd</p> \\[\\displaystyle \\sum_{i = 1}^d p(x_i | c) = 1, \\quad \\forall c\\]"},{"location":"course/ml-algorithms/nbc/#gaussian-naive-bayes","title":"Gaussian Naive Bayes","text":"<p>Th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho lo\u1ea1i d\u1eef li\u1ec7u m\u00e0 c\u00e1c th\u00e0nh ph\u1ea7n l\u00e0 c\u00e1c bi\u1ebfn li\u00ean t\u1ee5c.</p> \\[ \\tag{8} p(x_i|c) =  \\dfrac{1}{\\sqrt{2\\pi \\sigma_{ci}^2}} \\exp\\left(- \\dfrac{(x_i - \\mu_{ci})^2}{2 \\sigma_{ci}^2}\\right) \\]"},{"location":"course/ml-algorithms/nbc/#multinomial-naive-bayes","title":"Multinomial Naive Bayes","text":"<p>Th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho lo\u1ea1i d\u1eef li\u1ec7u m\u00e0 features vector \u0111\u01b0\u1ee3c t\u00ednh b\u1eb1ng Bags of Words.</p> \\[ \\tag{9} p(x_i | c) = \\dfrac{N_{ci}}{N_c} \\] <p>trong \u0111\u00f3:</p> <ul> <li>\\(N_{ci}\\): t\u1ed5ng s\u1ed1 l\u01b0\u1ee3ng word \\(x_i\\) trong class \\(c\\)h</li> <li>\\(N_c\\): t\u1ed5ng s\u1ed1 l\u01b0\u1ee3ng word c\u1ee7a class \\(c\\)</li> </ul> <p>C\u00e1ch t\u00ednh n\u00e0y c\u00f3 m\u1ed9t v\u1ea5n \u0111\u1ec1: n\u1ebfu t\u1eeb \\(x_i\\) ch\u01b0a bao gi\u1edd xu\u1ea5t hi\u1ec7n trong class \\(c\\) th\u00ec bi\u1ec3u th\u1ee9c \\((10)\\) s\u1ebd b\u1eb1ng \\(0\\), d\u1eabn \u0111\u1ebfn v\u1ebf ph\u1ea3i c\u1ee7a \\((6)\\) b\u1eb1ng \\(0\\) b\u1ea5t k\u1ec3 c\u00e1c gi\u00e1 tr\u1ecb kh\u00e1c c\u00f3 l\u1edbn th\u1ebf n\u00e0o.</p> <p>\u0110\u1ec3 kh\u1eafc ph\u1ee5c, m\u1ed9t k\u1ef9 thu\u1eadt \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 Laplace smoothing \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng:</p> \\[ \\tag{10} p(x_i | c) = \\dfrac{N_{ci} + \\alpha}{N_{c} + d\\alpha}, \\quad \\alpha &gt; 0 \\] <p>Th\u01b0\u1eddng th\u00ec ta l\u1ea5y \\(\\alpha = 1\\).</p> <p>Note</p> <p>C\u00f3 th\u1ec3 h\u00ecnh dung ph\u01b0\u01a1ng ph\u00e1p n\u00e0y l\u00e0 v\u1edbi m\u1ed7i class \\(c\\), v\u1edbi m\u1ed7i t\u1eeb \\(x_i\\), ta \u0111\u1ec1u th\u00eam s\u1eb5n m\u1ed9t s\u1ed1 l\u01b0\u1ee3ng \\(\\alpha\\) t\u1eeb \\(x_i\\).</p>"},{"location":"course/ml-algorithms/nbc/#bernoulli-naive-bayes","title":"Bernoulli Naive Bayes","text":"<p>Th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho lo\u1ea1i d\u1eef li\u1ec7u m\u00e0 m\u1ed7i th\u00e0nh ph\u1ea7n l\u00e0 m\u1ed9t gi\u00e1 tr\u1ecb binary.</p> \\[ \\tag{11} p\\left(x_i | c\\right) = p\\left(i | c\\right)^{x_i} \\left(1 - p\\left(i | c\\right)\\right) ^{1 - x_i} \\] <p>trong \u0111\u00f3 \\(p\\left(x_i | c\\right)\\) c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 x\u00e1c su\u1ea5t t\u1eeb th\u1ee9 \\(i\\) xu\u1ea5t hi\u1ec7n trong c\u00e1c v\u0103n b\u1ea3n c\u1ee7a class \\(c\\).</p>"},{"location":"course/ml-algorithms/nbc/#thuc-hanh","title":"Th\u1ef1c h\u00e0nh","text":"<p>Ph\u1ea7n n\u00e0y ta s\u1ebd x\u00e2y d\u1ef1ng c\u00e1c b\u01b0\u1edbc \u0111\u1ec3 gi\u1ea3i m\u1ed9t b\u00e0i to\u00e1n Navie Bayes Classifier s\u1eed d\u1ee5ng c\u00e1c ki\u1ebfn th\u1ee9c \u1edf tr\u00ean.</p> V\u00ed d\u1ee5: B\u1eafc hay Nam <p>Ta s\u1ebd th\u1ef1c h\u00e0nh tr\u00ean b\u00e0i to\u00e1n sau: Cho c\u00e1c v\u0103n b\u1ea3n \\(\\text{d1}\\), \\(\\text{d2}\\), \\(\\text{d3}\\), \\(\\text{d4}\\) nh\u01b0 trong b\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y. M\u1ed7i v\u0103n b\u1ea3n n\u00e0y thu\u1ed9c v\u00e0o 1 trong 2 classes: \\(\\text{B}\\) (B\u1eafc) ho\u1eb7c \\(\\text{N}\\) (Nam). H\u00e3y x\u00e1c \u0111\u1ecbnh class c\u1ee7a v\u0103n b\u1ea3n \\(\\text{d5}\\).</p> Document Content Class Training \\(\\text{d1}\\) \\(\\text{hanoi pho chaolong hanoi}\\) \\(\\text{B}\\) \\(\\text{d2}\\) \\(\\text{hanoi buncha pho omai}\\) \\(\\text{B}\\) \\(\\text{d3}\\) \\(\\text{pho bahngio omai}\\) \\(\\text{B}\\) \\(\\text{d4}\\) \\(\\text{saigon hutiu banhbo pho}\\) \\(\\text{N}\\) Test \\(\\text{d5}\\) \\(\\text{hanoi hanoi buncha hutiu}\\) \\(\\text{?}\\)"},{"location":"course/ml-algorithms/nbc/#training","title":"Training","text":"<ul> <li> <p>B\u01b0\u1edbc 1: T\u00ednh c\u00e1c \\(p(c)\\)</p> V\u00ed d\u1ee5: B\u1eafc hay Nam <p>V\u00ed d\u1ee5 ta \u0111ang x\u00e9t c\u00f3 2 class l\u00e0 \\(\\text{B}\\) v\u00e0 \\(\\text{N}\\). Ta s\u1ebd t\u00ednh c\u00e1c \\(p(\\text{B})\\) v\u00e0 \\(p(\\text{N})\\):</p> \\[ p(\\text{B}) = \\dfrac{3}{4}, \\quad\\quad p(\\text{N}) = \\dfrac{1}{4} \\] </li> <li> <p>B\u01b0\u1edbc 2: X\u00e1c \u0111\u1ecbnh \\(V = \\text{Bags of Words}\\), l\u00e0 t\u1eadp h\u1ee3p to\u00e0n b\u1ed9 c\u00e1c t\u1eeb trong v\u0103n b\u1ea3n.</p> V\u00ed d\u1ee5: B\u1eafc hay Nam \\[ V = \\{\\text{hanoi, pho, chaolong, buncha, omai, banhgio, saigon, hutiu, banhbo}\\}, \\quad \\lvert V \\rvert = 9 \\] </li> <li> <p>B\u01b0\u1edbc 3: V\u1edbi m\u1ed7i word \\(x_i \\in V\\), v\u1edbi m\u1ed7i class \\(c\\), t\u00ednh \\(p(x_i | c)\\).</p> V\u00ed d\u1ee5: B\u1eafc hay Nam <p>\u0110\u1ea7u ti\u00ean \u0111\u1ebfm s\u1ed1 t\u1eeb c\u1ee7a m\u1ed7i class, ta t\u00ednh \u0111\u01b0\u1ee3c class \\(\\text{B}\\) c\u00f3 t\u1ed5ng c\u1ed9ng \\(11\\) word v\u00e0 class \\(\\text{N}\\) c\u00f3 t\u1ed5ng c\u1ed9ng 4 word:</p> \\[ N_\\text{B} = 11, \\quad N_\\text{N} = 4 \\] <p>X\u00e9t class \\(\\text{B}\\), v\u00ed d\u1ee5 v\u1edbi word \\(\\text{hanoi}\\), trong t\u1ea5t c\u1ea3 c\u00e1c v\u0103n b\u1ea3n thu\u1ed9c class \\(\\text{B}\\), word \\(\\text{hanoi}\\) xu\u1ea5t hi\u1ec7n t\u1ed5ng c\u1ed9ng \\(3\\) l\u1ea7n.</p> <p>\u00c1p d\u1ee5ng \\((10)\\) v\u1edbi \\(\\alpha = 1\\), ta t\u00ednh \u0111\u01b0\u1ee3c:</p> \\[ p(\\text{hanoi} | \\text{B}) = \\dfrac{3 + 1}{11 + 9.1} = \\dfrac{4}{20} \\] <p>T\u01b0\u01a1ng t\u1ef1 v\u1edbi c\u00e1c word c\u00f2n l\u1ea1i v\u00e0 class \\(\\text{N}\\), ta t\u00ednh \u0111\u01b0\u1ee3c c\u00e1c \\(p(x_i | c)\\) nh\u01b0 sau (k\u00fd hi\u1ec7u \\(\\hat{\\lambda}\\) trong h\u00ecnh ch\u00ednh l\u00e0 \\(p\\)):</p> <p></p> </li> </ul>"},{"location":"course/ml-algorithms/nbc/#test","title":"Test","text":"<p>V\u1edbi m\u1ed7i v\u0103n b\u1ea3n m\u1edbi, ta th\u1ef1c hi\u1ec7n c\u00e1c b\u01b0\u1edbc sau:</p> <ul> <li> <p>B\u01b0\u1edbc 1: T\u00ednh \u0111i\u1ec3m d\u1eef li\u1ec7u \\(\\mathbf{x}\\) t\u01b0\u01a1ng \u1ee9ng</p> V\u00ed d\u1ee5: B\u1eafc hay Nam <p>V\u1edbi</p> \\[\\text{d5} = \\text{hanoi hanoi buncha hutiu}\\] <p>v\u00e0</p> \\[ V = \\{\\text{hanoi, pho, chaolong, buncha, omai, banhgio, saigon, hutiu, banhbo}\\} \\] <p>ta t\u00ednh \u0111\u01b0\u1ee3c \\(\\mathbf{x}_5 = \\left[ 2, 0, 0, 1, 0, 0, 0, 1, 0 \\right]\\).</p> </li> <li> <p>B\u01b0\u1edbc 2: X\u00e1c \u0111\u1ecbnh class c\u1ee7a n\u00f3 nh\u01b0 \u1edf \\((6)\\)</p> \\[ \\tag{6} c = \\arg\\max_{c \\in \\{1, \\dots, C\\}} p(c) \\prod_{i=1}^d p(x_i | c) \\] </li> </ul> <ol> <li> <p>https://machinelearningcoban.com/2017/08/08/nbc/\u00a0\u21a9</p> </li> </ol>"},{"location":"course/ml-algorithms/svm/","title":"Soft Margin Support Vector Machine","text":"<p>B\u00e0i n\u00e0y s\u1ebd n\u00f3i v\u1ec1 Soft Margin SVM v\u00e0 th\u1ef1c h\u00e0nh n\u00f3 tr\u00ean Python.</p> <p>\u0110\u1ecdc b\u00e0i g\u1ed1c \u1edf b\u00e0i vi\u1ebft tr\u00ean forum Machine Learning c\u01a1 b\u1ea3n.</p>"},{"location":"course/ml-algorithms/svm/#bai-toan","title":"B\u00e0i to\u00e1n","text":""},{"location":"course/system-design-interview/","title":"Mock System Design Interviews","text":""},{"location":"course/system-design-interview/#sources","title":"Sources","text":"<ul> <li>Mastering the System Design Interview</li> <li>System Design Interview \u2013 An insider's guide</li> </ul>"},{"location":"course/system-design-interview/#materials","title":"Materials","text":"<ul> <li>Slide Mastering the System Design Interview</li> <li>System Design Interview \u2013 An insider's guide book</li> </ul>"},{"location":"course/system-design-interview/#course-content","title":"Course content","text":"<ul> <li>Design a URL Shortening Service</li> <li>Design a Restaurant Reservation System</li> </ul>"},{"location":"course/system-design-interview/restaurant-reservation-system/","title":"Design a Restaurant Reservation System","text":""},{"location":"course/system-design-interview/url-shortening-service/","title":"Design a URL Shortening Service","text":"<p>Design something like bit.ly. A service where anyone can enter a URL, get a shorter URL to use in its place, and we manage redirecting them.</p>"},{"location":"course/system-design-interview/url-shortening-service/#qa","title":"Q&amp;A","text":"What sort of scale are we talking about? <p>Millions of redirects every day, and we dont want to make any design decision that migh limit us later, so assume millions of URLs as well.</p> Any restrictions on the characters we use? Symbols might be a little too hard for people to remember or type."},{"location":"leetcode/","title":"LeetCode Series","text":"<p>\u0110\u00e2y l\u00e0 t\u1ed5ng h\u1ee3p c\u00e1c b\u00e0i t\u1eadp tr\u00ean  LeetCode ch\u1ecdn l\u1ecdc c\u00f9ng c\u00e1ch gi\u1ea3i v\u00e0 code.</p> <p>V\u00ec c\u00e1c b\u00e0i t\u1eadp tr\u00ean  LeetCode th\u01b0\u1eddng kh\u00f4ng c\u00f3 format cho Input v\u00e0 Output n\u00ean c\u00f3 th\u1ec3 \u1edf d\u01b0\u1edbi s\u1ebd t\u1ef1 b\u1ecba.</p> <p>T\u00ean c\u00e1c bi\u1ebfn xu\u1ea5t hi\u1ec7n trong \u0111\u1ec1 b\u00e0i n\u1ebfu c\u1ea7n c\u0169ng s\u1ebd \u0111\u1ed5i lu\u00f4n cho n\u00f3 d\u1ec5 nh\u00ecn v\u1ec1 m\u1eb7t to\u00e1n h\u1ecdc.</p> <p>Gi\u1edbi h\u1ea1n r\u00e0ng bu\u1ed9c c\u1ee7a b\u00e0i to\u00e1n c\u00f3 th\u1ec3 c\u0169ng thay lu\u00f4n, v\u00ec nhi\u1ec1u khi  LeetCode \u0111\u1ec3 r\u00e0ng bu\u1ed9c qu\u00e1 l\u1ecfng.</p> <p>Ch\u1ee7 y\u1ebfu l\u00e0 \u0111\u1ec3 t\u00e1i s\u1eed d\u1ee5ng n\u1ebfu c\u1ea7n. C\u00e1c b\u00e0i to\u00e1n h\u1ea7u h\u1ebft s\u1ebd \u0111\u01b0\u1ee3c code b\u1eb1ng </p> <p>L\u01b0u \u00fd</p> <p>N\u1ebfu c\u00e1c c\u00f4ng th\u1ee9c to\u00e1n trong b\u00e0i vi\u1ebft kh\u00f4ng hi\u1ec3n th\u1ecb \u0111\u00fang, b\u1ea5m F5 \u0111\u1ec3 t\u1ea3i l\u1ea1i trang l\u1ea7n n\u1eefa.</p>"},{"location":"leetcode/#danh-sach-cac-bai-tap-leetcode","title":"Danh s\u00e1ch c\u00e1c b\u00e0i t\u1eadp LeetCode","text":""},{"location":"leetcode/#0-999","title":"0 - 999","text":"<ul> <li>239.\u00a0Sliding Window Maximum Hard</li> <li>714.\u00a0Best Time to Buy and Sell Stock with Transaction Fee Medium</li> </ul>"},{"location":"leetcode/#1000-1999","title":"1000 - 1999","text":"<ul> <li>1175.\u00a0Prime Arrangements Easy</li> </ul>"},{"location":"leetcode/#2000-2999","title":"2000 - 2999","text":"<ul> <li>2453.\u00a0Destroy Sequential Targets Medium</li> <li>2485.\u00a0Find the Pivot Integer Easy</li> </ul>"},{"location":"leetcode/#3000-3999","title":"3000 - 3999","text":"<ul> <li>3227. Vowels Game in a String Medium</li> </ul>"},{"location":"leetcode/1175/","title":"1175.\u00a0Prime Arrangements","text":"<p>Easy</p> <p>Cho s\u1ed1 t\u1ef1 nhi\u00ean \\(n\\), tr\u1ea3 v\u1ec1 s\u1ed1 ho\u00e1n v\u1ecb c\u1ee7a c\u00e1c s\u1ed1 t\u1eeb \\(1\\) \u0111\u1ebfn \\(n\\) sao cho c\u00e1c s\u1ed1 nguy\u00ean t\u1ed1 \u0111\u1ee9ng \u1edf c\u00e1c v\u1ecb tr\u00ed nguy\u00ean t\u1ed1 (v\u1ecb tr\u00ed \u0111\u01b0\u1ee3c \u0111\u00e1nh s\u1ed1 b\u1eaft \u0111\u1ea7u t\u1eeb \\(1\\)).</p> <p>V\u00ec k\u1ebft qu\u1ea3 c\u00f3 th\u1ec3 r\u1ea5t l\u1edbn n\u00ean tr\u1ea3 v\u1ec1 k\u1ebft qu\u1ea3 sau khi chia l\u1ea5y d\u01b0 cho \\(10^9+7\\).</p> <p>Input</p> <ul> <li>G\u1ed3m m\u1ed9t d\u00f2ng duy nh\u1ea5t ch\u1ee9a \\(n\\)</li> </ul> <p>Output</p> <ul> <li>G\u1ed3m m\u1ed9t d\u00f2ng duy nh\u1ea5t l\u00e0 k\u1ebft qu\u1ea3 c\u1ee7a b\u00e0i to\u00e1n</li> </ul> <p>R\u00e0ng bu\u1ed9c</p> <ul> <li>\\(1 \\leq n \\leq 100\\)</li> </ul> <p>V\u00ed d\u1ee5</p> <p>V\u00ed d\u1ee5 1</p> <p>Input<pre><code>5\n</code></pre> Output<pre><code>12\n</code></pre> Gi\u1ea3i th\u00edch: Ch\u1eb3ng h\u1ea1n ho\u00e1n v\u1ecb \\([1, 2, 5, 4, 3]\\) l\u00e0 m\u1ed9t ho\u00e1n v\u1ecb tho\u1ea3 m\u00e3n, nh\u01b0ng ho\u00e1n v\u1ecb \\([5, 2, 3, 4, 1]\\) th\u00ec kh\u00f4ng.</p> <p>V\u00ed d\u1ee5 2</p> <p>Input<pre><code>100\n</code></pre> Output<pre><code>682289015\n</code></pre></p> Link n\u1ed9p b\u00e0i <p> 1175.\u00a0Prime Arrangements</p> Solution <p>Gi\u1ea3 s\u1eed c\u00f3 \\(p\\) s\u1ed1 nguy\u00ean t\u1ed1 trong \u0111o\u1ea1n t\u1eeb \\(1\\) \u0111\u1ebfn \\(n\\). V\u00ec c\u00e1c s\u1ed1 nguy\u00ean t\u1ed1 ch\u1ec9 c\u00f3 th\u1ec3 \u1edf v\u1ecb tr\u00ed nguy\u00ean t\u1ed1 n\u00ean ta c\u00f3 \\(p!\\) c\u00e1ch ch\u1ecdn v\u1ecb tr\u00ed cho \\(p\\) s\u1ed1 n\u00e0y.</p> <p>V\u1edbi m\u1ed7i c\u00e1ch ch\u1ecdn v\u1ecb tr\u00ed cho \\(p\\) s\u1ed1 nguy\u00ean t\u1ed1, ta c\u00f3 \\((n - p)!\\) c\u00e1ch ch\u1ecdn v\u1ecb tr\u00ed cho c\u00e1c s\u1ed1 c\u00f2n l\u1ea1i.</p> <p>Nh\u01b0 v\u1eady k\u1ebft qu\u1ea3 b\u00e0i to\u00e1n l\u00e0:</p> \\[ p!(n-p)! \\] <p>v\u1edbi \\(p\\) l\u00e0 s\u1ed1 s\u1ed1 nguy\u00ean t\u1ed1 t\u1eeb \\(1\\) \u0111\u1ebfn \\(n\\).</p> <p>Nh\u01b0 v\u1eady ch\u1ec9 c\u1ea7n t\u00ecm \\(p\\) l\u00e0 s\u1ed1 l\u01b0\u1ee3ng s\u1ed1 nguy\u00ean t\u1ed1 t\u1eeb \\(1\\) \u0111\u1ebfn \\(n\\) l\u00e0 ta c\u00f3 th\u1ec3 gi\u1ea3i b\u00e0i to\u00e1n n\u00e0y.</p> <p>\u0110\u1ec1 b\u00e0i ch\u1ec9 cho gi\u1edbi h\u1ea1n \\(n \\leq 100\\) n\u00ean th\u00edch qu\u1ea9y s\u00e0ng nguy\u00ean t\u1ed1 hay c\u00e1i g\u00ec c\u0169ng \u0111\u01b0\u1ee3c.</p> Code  C++ Python <pre><code>class Solution {\npublic:\n    const long long MOD = 1000000007;\n\n    long long numPrimeArrangements(long long n) {\n\n        // S\u00e0ng nguy\u00ean t\u1ed1\n        vector&lt;bool&gt; isPrime(n + 1, true);\n        isPrime[0] = false;\n        isPrime[1] = false;\n\n        for (int i = 2; i * i &lt;= n; i++) {\n            if (isPrime[i])\n                for (int j = i * i; j &lt;= n; j += i) {\n                    isPrime[j] = false;\n                }\n        }\n\n        // \u0110\u1ebfm s\u1ed1 s\u1ed1 nguy\u00ean t\u1ed1 trong kho\u1ea3ng t\u1eeb 1 \u0111\u1ebfn n\n        long long count = 0;\n        for (long long i = 0; i &lt;= n; i++) {\n            if (isPrime[i])\n                count++;\n        }\n\n        // T\u00ednh k\u1ebft qu\u1ea3\n        long long result = 1;\n        for (long long i = 1; i &lt;= count; i++) {\n            result = (result * i) % MOD;\n        }\n        for (long long i = 1; i &lt;= n - count; i++) {\n            result = (result * i) % MOD;\n        }\n\n        return result;\n    }\n};\n</code></pre> <pre><code>class Solution:\n    def numPrimeArrangements(self, n: int) -&gt; int:\n        MOD = int(1e9 + 7)\n\n        is_prime = [True] * (n + 1)\n        is_prime[0] = False\n        is_prime[1] = False\n\n        for i in range(2, int(n ** .5) + 1):\n            for j in range(i * i, n + 1, i):\n                is_prime[j] = False\n\n        count = 0\n        for i in range(n + 1):\n            if is_prime[i]:\n                count += 1\n\n        ans = 1\n        for i in range(1, count + 1):\n            ans = (ans * i) % MOD\n        for i in range(1, n - count + 1):\n            ans = (ans * i) % MOD\n\n        return ans\n</code></pre>"},{"location":"leetcode/239/","title":"239.\u00a0Sliding Window Maximum","text":"<p>Hard</p> <p>Cho m\u1ed9t m\u1ea3ng <code>nums</code> g\u1ed3m \\(n\\) s\u1ed1 nguy\u00ean, t\u00ecm \\(\\max\\) c\u1ee7a t\u1ea5t c\u1ea3 c\u00e1c d\u00e3y con \\(k\\) ph\u1ea7n t\u1eed c\u1ee7a <code>nums</code>.  M\u1ed9t d\u00e3y con l\u00e0 m\u1ed9t d\u00e3y li\u00ean ti\u1ebfp c\u00e1c ph\u1ea7n t\u1eed. In k\u1ebft qu\u1ea3 ra theo \u0111\u00fang th\u1ee9 t\u1ef1 c\u1ee7a c\u00e1c d\u00e3y con t\u01b0\u01a1ng \u1ee9ng.</p> <p>R\u00e0ng bu\u1ed9c</p> <ul> <li>\\(1 \\leq k \\leq n \\leq 10^5\\)</li> <li>\\(-10^4 \\leq\\) <code>nums[i]</code> \\(\\leq 10^4\\)</li> </ul> <p>V\u00ed d\u1ee5</p> <p>V\u00ed d\u1ee5 1</p> <p>Input<pre><code>nums = [1,3,-1,-3,5,3,6,7], k = 3\n</code></pre> Output<pre><code>[3,3,5,5,6,7]\n</code></pre> Gi\u1ea3i th\u00edch:  <pre><code>Window position                Max\n---------------               -----\n[1  3  -1] -3  5  3  6  7       3\n 1 [3  -1  -3] 5  3  6  7       3\n 1  3 [-1  -3  5] 3  6  7       5\n 1  3  -1 [-3  5  3] 6  7       5\n 1  3  -1  -3 [5  3  6] 7       6\n 1  3  -1  -3  5 [3  6  7]      7\n</code></pre></p> <p>V\u00ed d\u1ee5 2</p> <p>Input<pre><code>nums = [1], k = 1\n</code></pre> Output<pre><code>[1]\n</code></pre></p> Link n\u1ed9p b\u00e0i <p> 239. Sliding Window Maximum</p> Solution <p>S\u1eed d\u1ee5ng deque.</p> <p>Kh\u1edfi t\u1ea1o m\u1ea3ng <code>ans</code> l\u01b0u k\u1ebft qu\u1ea3.</p> <p>Khi x\u00e9t \u0111\u1ebfn ph\u1ea7n t\u1eed <code>i</code>:</p> <ul> <li><code>pop_back</code> n\u1ebfu back c\u1ee7a queue l\u00e0 ph\u1ea7n t\u1eed kh\u00f4ng n\u1eb1m trong sliding window <code>[i - k + 1, i]</code></li> <li><code>pop_front</code> cho \u0111\u1ebfn khi queue r\u1ed7ng ho\u1eb7c front c\u1ee7a queue l\u1edbn h\u01a1n <code>nums[i]</code></li> <li><code>push</code> ph\u1ea7n t\u1eed <code>i</code> v\u00e0o front c\u1ee7a queue. Nh\u01b0 v\u1eady c\u00e1c ph\u1ea7n t\u1eed trong queue s\u1ebd lu\u00f4n \u0111\u1ea3m b\u1ea3o l\u00e0 ch\u1ec9 ch\u1ee9a c\u00e1c s\u1ed1 trong sliding window v\u00e0 back c\u1ee7a queue lu\u00f4n l\u00e0 ph\u1ea7n t\u1eed l\u1edbn nh\u1ea5t.</li> <li>Th\u00eam ph\u1ea7n t\u1eed \u1edf ph\u00eda sau <code>queue</code> v\u00e0o <code>ans</code>.</li> </ul> <p>\u0110\u1ed9 ph\u1ee9c t\u1ea1p l\u00e0 \\(\\text{O}(n)\\), v\u00ec m\u1ed7i ph\u1ea7n t\u1eed ch\u1ec9 \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o v\u00e0 l\u1ea5y kh\u1ecfi queue nhi\u1ec1u nh\u1ea5t 1 l\u1ea7n.</p> Code  C++ Python <pre><code>class Solution {\npublic:\n    vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt; &amp;nums, int k) {\n        if (k == 1)\n            return nums;\n\n        vector&lt;int&gt; ans;\n\n        deque&lt;int&gt; dq;\n\n        for (int i = 0; i &lt; nums.size(); i++) {\n            while (!dq.empty() &amp;&amp; i - dq.back() &gt;= k)\n                dq.pop_back();\n            while (!dq.empty() &amp;&amp; nums[dq.front()] &lt;= nums[i])\n                dq.pop_front();\n            dq.push_front(i);\n            if (i &gt;= k - 1) {\n                ans.push_back(nums[dq.back()]);\n            }\n        }\n\n        return ans;\n    }\n};\n</code></pre> <pre><code>\n</code></pre>"},{"location":"leetcode/2453/","title":"2453.\u00a0Destroy Sequential Targets","text":"<p>Medium</p> <p>Cho m\u1ea3ng <code>nums</code> \u0111\u01b0\u1ee3c \u0111\u00e1nh s\u1ed1 b\u1eaft \u0111\u1ea7u t\u1eeb \\(0\\) v\u00e0 g\u1ed3m c\u00e1c s\u1ed1 nguy\u00ean d\u01b0\u01a1ng. M\u1ed7i s\u1ed1 c\u1ee7a m\u1ea3ng <code>nums</code> bi\u1ec3u di\u1ec5n m\u1ed9t m\u1ee5c ti\u00eau \u1edf tr\u00ean tr\u1ee5c s\u1ed1. Ngo\u00e0i ra b\u1ea1n \u0111\u01b0\u1ee3c cho m\u1ed9t s\u1ed1 nguy\u00ean d\u01b0\u01a1ng <code>space</code>.</p> <p>B\u1ea1n c\u00f3 m\u1ed9t c\u1ed7 m\u00e1y c\u00f3 th\u1ec3 ti\u00eau di\u1ec7t c\u00e1c m\u1ee5c ti\u00eau. N\u1ebfu n\u1ea1p cho m\u00e1y m\u1ed9t s\u1ed1 <code>nums[i]</code> th\u00ec m\u00e1y s\u1ebd ti\u00eau di\u1ec7t \u0111\u01b0\u1ee3c t\u1ea5t c\u1ea3 c\u00e1c s\u1ed1 nguy\u00ean c\u00f3 d\u1ea1ng <code>nums[i] + c * space</code>, trong \u0111\u00f3 <code>c</code> l\u00e0 m\u1ed9t s\u1ed1 nguy\u00ean kh\u00f4ng \u00e2m b\u1ea5t k\u1ef3. B\u1ea1n mu\u1ed1n ti\u00eau di\u1ec7u nhi\u1ec1u m\u1ee5c ti\u00eau trong m\u1ea3ng <code>nums</code> nh\u1ea5t c\u00f3 th\u1ec3.</p> <p>Y\u00eau c\u1ea7u: H\u00e3y t\u00ecm gi\u00e1 tr\u1ecb <code>nums[i]</code> nh\u1ecf nh\u1ea5t m\u00e0 b\u1ea1n c\u00f3 th\u1ec3 n\u1ea1p cho c\u1ed7 m\u00e1y sao cho s\u1ed1 l\u01b0\u1ee3ng m\u1ee5c ti\u00eau trong m\u1ea3ng <code>nums</code> b\u1ecb ti\u00eau di\u1ec7t l\u00e0 nhi\u1ec1u nh\u1ea5t.</p> <p>R\u00e0ng bu\u1ed9c</p> <ul> <li>\\(1 \\leq\\) <code>nums.length</code> \\(\\leq 10^5\\)</li> <li>\\(1 \\leq\\) <code>nums[i]</code> \\(\\leq 10^9\\)</li> <li>\\(1 \\leq\\) <code>space</code> \\(\\leq 10^9\\)</li> </ul> <p>V\u00ed d\u1ee5</p> <p>V\u00ed d\u1ee5 1</p> <p>Input<pre><code>nums = [3,7,8,1,1,5], space = 2\n</code></pre> Output<pre><code>1\n</code></pre> Gi\u1ea3i th\u00edch: Ta ch\u1ecdn <code>nums[3]</code> \u0111\u1ec3 n\u1ea1p cho c\u1ed7 m\u00e1y. C\u1ed7 m\u00e1y s\u1ebd ti\u00eau di\u1ec7t \u0111\u01b0\u1ee3c 5 m\u1ee5c ti\u00eau l\u00e0 <code>1</code>, <code>3</code>, <code>5</code>, <code>7</code>, <code>9</code>. Kh\u00f4ng c\u00f3 c\u00e1ch n\u00e0o ti\u00eau di\u1ec7t \u0111\u01b0\u1ee3c nhi\u1ec1u h\u01a1n 5 m\u1ee5c ti\u00eau.</p> <p>V\u00ed d\u1ee5 2</p> <p>Input<pre><code>nums = [1,3,5,2,4,6], space = 2\n</code></pre> Output<pre><code>1\n</code></pre> Gi\u1ea3i th\u00edch: Ta ch\u1ecdn <code>nums[0]</code> ho\u1eb7c <code>nums[3]</code> \u0111\u1ec3 n\u1ea1p cho c\u1ed7 m\u00e1y, c\u1ed7 m\u00e1y c\u00f3 th\u1ec3 ti\u00eau di\u1ec7t \u0111\u01b0\u1ee3c 3 m\u1ee5c ti\u00eau. Kh\u00f4ng c\u00f3 c\u00e1ch n\u00e0o ti\u00eau di\u1ec7t \u0111\u01b0\u1ee3c nhi\u1ec1u h\u01a1n 3 m\u1ee5c ti\u00eau. V\u00ec <code>nums[0]</code> \\(&lt;\\) <code>nums[3]</code> n\u00ean ta ch\u1ecdn <code>nums[0]</code>.</p> Link n\u1ed9p b\u00e0i <p> 2453.\u00a0Destroy Sequential Targets</p> Solution <p>Nh\u1eadn x\u00e9t: Khi n\u1ea1p cho c\u1ed7 m\u00e1y m\u1ed9t s\u1ed1 <code>x</code> th\u00ec t\u1ea5t c\u1ea3 c\u00e1c s\u1ed1 c\u00f3 c\u00f9ng s\u1ed1 d\u01b0 v\u1edbi <code>x</code> khi chia cho <code>space</code> \u0111\u1ec1u s\u1ebd b\u1ecb ti\u00eau di\u1ec7t.</p> <p>V\u1eady ta c\u1ea7n t\u00ecm <code>nums[i]</code> sao cho trong m\u1ea3ng <code>nums</code> ch\u1ee9a nhi\u1ec1u s\u1ed1 c\u00f3 c\u00f9ng s\u1ed1 d\u01b0 v\u1edbi n\u00f3 nh\u1ea5t khi chia cho <code>space</code>. Ta l\u00e0m nh\u01b0 sau:</p> <ul> <li>T\u1ea1o m\u1ed9t hash table <code>counts</code> trong \u0111\u00f3 <code>counts[x]</code> l\u00e0 s\u1ed1 l\u01b0\u1ee3ng ph\u1ea7n t\u1eed trong m\u1ea3ng <code>nums</code> chia cho <code>space</code> d\u01b0 <code>x</code>.</li> <li>T\u00ecm <code>maxTarget</code> l\u00e0 \\(\\max\\) c\u1ee7a <code>counts</code></li> <li>Trong c\u00e1c <code>nums[i]</code> c\u00f3 <code>counts[nums[i] % space] == maxTarget</code>, ch\u1ecdn ra s\u1ed1 nh\u1ecf nh\u1ea5t. \u0110\u00f3 ch\u00ednh l\u00e0 k\u1ebft qu\u1ea3 b\u00e0i to\u00e1n.</li> </ul> Code  C++ Python <pre><code>class Solution {\npublic:\n    int destroyTargets(vector&lt;int&gt; &amp;nums, int space) {\n        unordered_map&lt;int, int&gt; counts;\n\n        int maxTarget = 0;\n        for (int i = 0; i &lt; nums.size(); i++) {\n            int x = nums[i] % space;\n            maxTarget = max(maxTarget, ++counts[x]);\n        }\n\n        int ans = 1e9;\n        for (int i = 0; i &lt; nums.size(); i++)\n            if (counts[nums[i] % space] == maxTarget)\n                ans = min(ans, nums[i]);\n\n        return ans;\n    }\n};\n</code></pre> <pre><code>class Solution:\n    def destroyTargets(self, nums: List[int], space: int) -&gt; int:\n        counts = defaultdict(int)\n        maxTarget = 0\n\n        for num in nums:\n            x = num % space\n            counts[x] += 1\n            maxTarget = max(maxTarget, counts[x])\n\n        return min(n for n in nums if counts[n % space] == maxTarget)\n</code></pre>"},{"location":"leetcode/2485/","title":"2485.\u00a0Find the Pivot Integer","text":"<p>Easy</p> <p>Cho m\u1ed9t s\u1ed1 t\u1ef1 nhi\u00ean \\(n\\). H\u00e3y t\u00ecm s\u1ed1 t\u1ef1 nhi\u00ean \\(x\\) sao cho t\u1ed5ng c\u1ee7a c\u00e1c s\u1ed1 t\u1eeb \\(1\\) \u0111\u1ebfn \\(x\\) b\u1eb1ng t\u1ed5ng c\u1ee7a c\u00e1c s\u1ed1 t\u1eeb \\(x\\) \u0111\u1ebfn \\(n\\). N\u1ebfu kh\u00f4ng c\u00f3 s\u1ed1 t\u1ef1 nhi\u00ean n\u00e0o tho\u1ea3 m\u00e3n th\u00ec in ra \\(-1\\).</p> <p>Input</p> <ul> <li>G\u1ed3m m\u1ed9t d\u00f2ng duy nh\u1ea5t ch\u1ee9a \\(n\\)</li> </ul> <p>Output</p> <ul> <li>G\u1ed3m m\u1ed9t d\u00f2ng duy nh\u1ea5t l\u00e0 k\u1ebft qu\u1ea3 c\u1ee7a b\u00e0i to\u00e1n</li> </ul> <p>R\u00e0ng bu\u1ed9c</p> <ul> <li>\\(1 \\leq n \\leq 10^3\\)</li> </ul> <p>V\u00ed d\u1ee5</p> <p>V\u00ed d\u1ee5 1</p> <p>Input<pre><code>8\n</code></pre> Output<pre><code>6\n</code></pre> Gi\u1ea3i th\u00edch: \\(1 + 2 + 3 + 4 + 5 + 6 = 6 + 7 + 8 = 21\\).</p> <p>V\u00ed d\u1ee5 2</p> <p>Input<pre><code>1\n</code></pre> Output<pre><code>1\n</code></pre></p> <p>V\u00ed d\u1ee5 3</p> <p>Input<pre><code>4\n</code></pre> Output<pre><code>-1\n</code></pre></p> Link n\u1ed9p b\u00e0i <p> 2485.\u00a0Find the Pivot Integer</p> Solution <p>To\u00e1n th\u00f4ng th\u01b0\u1eddng:</p> \\[ \\begin{align*}     &amp;&amp;1 + 2 + \\dots + x &amp;= x + (x + 1) + \\dots + n \\\\  \\Leftrightarrow &amp;&amp;\\dfrac{x(x+ 1)}{2} &amp;= \\dfrac{n(n+ 1)}{2} - \\dfrac{(x - 1)x}{2} \\\\  \\Leftrightarrow &amp;&amp; 2x^2 &amp;= n(n+1) \\\\  \\Leftrightarrow &amp;&amp; x &amp;= \\sqrt{\\dfrac{n(n + 1)}{2}}, \\quad \\text{do } x &gt; 0 \\end{align*} \\] <p>Nh\u01b0 v\u1eady ta ch\u1ec9 c\u1ea7n ki\u1ec3m tra \\(\\dfrac{n(n + 1)}{2}\\) c\u00f3 ph\u1ea3i s\u1ed1 ch\u00ednh ph\u01b0\u01a1ng kh\u00f4ng l\u00e0 \u0111\u01b0\u1ee3c. N\u1ebfu c\u00f3 th\u00ec tr\u1ea3 v\u1ec1 \\(x\\) nh\u01b0 gi\u1ea3i \u1edf tr\u00ean, n\u1ebfu kh\u00f4ng th\u00ec tr\u1ea3 v\u1ec1 <code>-1</code>.</p> <p>\u0110\u1ed9 ph\u1ee9c t\u1ea1p l\u00e0 \\(\\text{O}(1)\\). B\u00e0i n\u00e0y \u0111\u00e1ng l\u1ebd ph\u1ea3i cho gi\u1edbi h\u1ea1n \\(n\\) l\u00e0 \\(10^9\\).</p> Code  C++ Python <pre><code>class Solution {\npublic:\n    int pivotInteger(int n) {\n        int x = (int) sqrt((n * n + n) / 2);\n        return 2 * x * x == n * (n + 1) ? x : -1;\n    }\n};\n</code></pre> <pre><code>class Solution:\ndef pivotInteger(self, n: int) -&gt; int:\n    ans = int((n * (n + 1) // 2) ** .5)\n    if ans * ans == n * (n + 1) // 2:\n        return ans\n    else:\n        return -1\n</code></pre>"},{"location":"leetcode/3227/","title":"3227. Vowels Game in a String","text":"<p>Medium</p> <p>Alice v\u00e0 Bob \u0111ang ch\u01a1i m\u1ed9t tr\u00f2 ch\u01a1i tr\u00ean x\u00e2u.</p> <p>B\u1ea1n \u0111\u01b0\u1ee3c cho m\u1ed9t x\u00e2u <code>s</code>, Alice v\u00e0 Bob s\u1ebd l\u1ea7n l\u01b0\u1ee3t ch\u01a1i nh\u01b0 sau:</p> <ul> <li>\u1ede l\u01b0\u1ee3t ch\u01a1i c\u1ee7a Alice, ph\u1ea3i xo\u00e1 \u0111i m\u1ed9t x\u00e2u con kh\u00e1c r\u1ed7ng c\u1ee7a <code>s</code> sao cho x\u00e2u con \u0111\u00f3 ch\u1ee9a m\u1ed9t s\u1ed1 l\u1ebb c\u00e1c nguy\u00ean \u00e2m.</li> <li>\u1edf l\u01b0\u1ee3t ch\u01a1i c\u1ee7a Bob, ph\u1ea3i xo\u00e1 \u0111i m\u1ed9t x\u00e2u con kh\u00e1c r\u1ed7ng c\u1ee7a <code>s</code> sao cho x\u00e2u con \u0111\u00f3 ch\u1ee9a m\u1ed9t s\u1ed1 ch\u1eb5n c\u00e1c nguy\u00ean \u00e2m.</li> </ul> <p>Alice l\u00e0 ng\u01b0\u1eddi ch\u01a1i tr\u01b0\u1edbc. Ng\u01b0\u1eddi ch\u01a1i n\u00e0o \u0111\u1ebfn l\u01b0\u1ee3t c\u1ee7a m\u00ecnh kh\u00f4ng th\u1ec3 th\u1ef1c hi\u1ec7n \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u s\u1ebd l\u00e0 ng\u01b0\u1eddi thua cu\u1ed9c.</p> <p>Tr\u1ea3 v\u1ec1 <code>true</code> n\u1ebfu Alice l\u00e0 ng\u01b0\u1eddi th\u1eafng trong tr\u00f2 ch\u01a1i. Gi\u1ea3 thi\u1ebft r\u1eb1ng c\u1ea3 2 ng\u01b0\u1eddi ch\u01a1i \u0111\u1ec1u ch\u01a1i m\u1ed9t c\u00e1ch t\u1ed1i \u01b0u.</p> <p>R\u00e0ng bu\u1ed9c:</p> <ul> <li>\\(1 \\leq\\) <code>s.length</code> \\(\\leq 10^5\\)</li> <li><code>s</code> ch\u1ec9 bao g\u1ed3m c\u00e1c ch\u1eef c\u00e1i ti\u1ebfng Anh vi\u1ebft th\u01b0\u1eddng.</li> </ul> <p>V\u00ed d\u1ee5</p> <p>V\u00ed d\u1ee5 1</p> <p>Input<pre><code>s = \"leetcoder\"\n</code></pre> Output<pre><code>true\n</code></pre> Gi\u1ea3i th\u00edch:</p> <ul> <li>Alice ch\u01a1i tr\u01b0\u1edbc, xo\u00e1 x\u00e2u con <code>leetco</code>, x\u00e2u <code>s</code> c\u00f2n l\u1ea1i <code>der</code></li> <li>Bob ch\u01a1i ti\u1ebfp, ch\u1ec9 c\u00f3 th\u1ec3 xo\u00e1 <code>d</code> ho\u1eb7c <code>r</code>, x\u00e2u <code>s</code> c\u00f2n l\u1ea1i <code>er</code> ho\u1eb7c <code>de</code></li> <li>Alicie ch\u01a1i ti\u1ebfp, d\u00f9 \u1edf l\u01b0\u1ee3t tr\u01b0\u1edbc Bob c\u00f3 ch\u01a1i th\u1ebf n\u00e0o th\u00ec \u1edf l\u01b0\u1ee3t n\u00e0y Alice \u0111\u1ec1u c\u00f3 th\u1ec3 xo\u00e1 to\u00e0n b\u1ed9 x\u00e2u <code>s</code></li> <li>Bob ch\u01a1i ti\u1ebfp v\u00e0 kh\u00f4ng th\u1ec3 th\u1ef1c hi\u1ec7n \u0111\u01b0\u1ee3c l\u01b0\u1ee3t ch\u01a1i c\u1ee7a m\u00ecnh, v\u00ec th\u1ebf Alice th\u1eafng.</li> </ul> <p>V\u00ed d\u1ee5 2</p> <p>Input<pre><code>s = \"bbcd\"\n</code></pre> Output<pre><code>false\n</code></pre> Gi\u1ea3i th\u00edch: Alice ch\u01a1i \u0111\u1ea7u ti\u00ean v\u00e0 kh\u00f4ng th\u1ec3 th\u1ef1c hi\u1ec7n \u0111\u01b0\u1ee3c l\u01b0\u1ee3t ch\u01a1i c\u1ee7a m\u00ecnh, v\u00ec th\u1ebf Alice thua.</p> Link n\u1ed9p b\u00e0i <p> 3227. Vowels Game in a String</p> Solution <p>D\u1ec5 th\u1ea5y n\u1ebfu <code>s</code> kh\u00f4ng c\u00f3 nguy\u00ean \u00e2m n\u00e0o, ch\u1eafc ch\u1eafn Alice thua.</p> <p>N\u1ebfu <code>s</code> c\u00f3 \\(k\\) nguy\u00ean \u00e2m (\\(k &gt; 0\\)), ta chia l\u00e0m 2 tr\u01b0\u1eddng h\u1ee3p:</p> <ul> <li>N\u1ebfu \\(k\\) l\u1ebb, Alice c\u00f3 th\u1ec3 xo\u00e1 to\u00e0n b\u1ed9 x\u00e2u <code>s</code> \u1edf l\u01b0\u1ee3t \u0111\u1ea7u ti\u00ean v\u00e0 ch\u1eafc ch\u1eafn th\u1eafng do \u1edf l\u01b0\u1ee3t ti\u1ebfp theo Bob kh\u00f4ng th\u1ec3 th\u1ef1c hi\u1ec7n l\u01b0\u1ee3t ch\u01a1i c\u1ee7a m\u00ecnh.</li> <li>N\u1ebfu \\(k\\) ch\u1eb5n, Alice c\u00f3 th\u1ec3 th\u1eafng b\u1eb1ng c\u00e1ch sau:<ul> <li>L\u01b0\u1ee3t 1: Alice xo\u00e1 \u0111i 1 nguy\u00ean \u00e2m b\u1ea5t k\u1ef3. X\u00e2u <code>s</code> b\u00e2y gi\u1edd c\u00f3 s\u1ed1 nguy\u00ean \u00e2m l\u00e0 l\u1ebb</li> <li>L\u01b0\u1ee3t 2: Bob ph\u1ea3i xo\u00e1 \u0111i m\u1ed9t s\u1ed1 ch\u1eb5n c\u00e1c nguy\u00ean \u00e2m, x\u00e2u <code>s</code> b\u00e2y gi\u1edd c\u00f3 s\u1ed1 nguy\u00ean \u00e2m l\u00e0 l\u1ebb v\u00e0 kh\u00f4ng th\u1ec3 l\u00e0 x\u00e2u r\u1ed7ng.</li> <li>L\u01b0\u1ee3t 3: Alice xo\u00e1 to\u00e0n b\u1ed9 x\u00e2u <code>s</code>. X\u00e2u <code>s</code> b\u00e2y gi\u1edd l\u00e0 x\u00e2u r\u1ed7ng.</li> <li>L\u01b0\u1ee3t 4: Bob kh\u00f4ng th\u1ec3 th\u1ef1c hi\u1ec7n l\u01b0\u1ee3t ch\u01a1i c\u1ee7a m\u00ecnh. Alice th\u1eafng.</li> </ul> </li> </ul> <p>V\u1eady, Alice thua n\u1ebfu x\u00e2u <code>s</code> kh\u00f4ng c\u00f3 nguy\u00ean \u00e2m n\u00e0o v\u00e0 th\u1eafng trong tr\u01b0\u1eddng h\u1ee3p ng\u01b0\u1ee3c l\u1ea1i.</p> Code  C++ Python <pre><code>class Solution {\npublic:\n    bool doesAliceWin(string s) {\n        for (char c : s)\n            if (c == 'a' || c == 'i' || c == 'o' || c == 'e' || c == 'u') return true;\n        return false;   \n    }\n};\n</code></pre> <pre><code>class Solution:\n    def doesAliceWin(self, s: str) -&gt; bool:\n        for c in s:\n            if c in \"aoeiu\": return True\n        return False\n</code></pre>"},{"location":"leetcode/714/","title":"714.\u00a0Best Time to Buy and Sell Stock with Transaction Fee","text":"<p>Medium</p> <p>Cho m\u1ea3ng <code>prices</code> g\u1ed3m <code>n</code> ph\u1ea7n t\u1eed, trong \u0111\u00f3 <code>prices[i]</code> l\u00e0 gi\u00e1 c\u1ee7a m\u1ed9t lo\u1ea1i c\u1ed5 phi\u1ebfu v\u00e0o ng\u00e0y th\u1ee9 <code>i</code>. Ph\u00ed giao d\u1ecbch l\u00e0 <code>fee</code>.</p> <p>H\u00e3y t\u00ecm l\u1ee3i nhu\u1eadn t\u1ed1i \u0111a c\u00f3 th\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c nh\u1edd vi\u1ec7c mua b\u00e1n c\u1ed5 phi\u1ebfu. B\u1ea1n c\u00f3 th\u1ec3 giao d\u1ecbch bao nhi\u00eau l\u1ea7n b\u1ea1n mu\u1ed1n, nh\u01b0ng b\u1ea1n c\u1ea7n ph\u1ea3i tr\u1ea3 <code>fee</code> \u0111\u1ed3ng cho m\u1ed7i giao d\u1ecbch.</p> <p>L\u01b0u \u00fd: B\u1ea1n kh\u00f4ng \u0111\u01b0\u1ee3c ph\u00e9p tham gia nhi\u1ec1u giao d\u1ecbch c\u00f9ng m\u1ed9t l\u00fac, ngh\u0129a l\u00e0 b\u1ea1n ph\u1ea3i b\u00e1n c\u1ed5 phi\u1ebfu th\u00ec m\u1edbi \u0111\u01b0\u1ee3c ti\u1ebfp t\u1ee5c mua l\u1ea1i.</p> <p>Input</p> <ul> <li>D\u00f2ng \u0111\u1ea7u ti\u00ean ch\u1ee9a 2 s\u1ed1 nguy\u00ean <code>n</code> v\u00e0 <code>fee</code></li> <li>D\u00f2ng th\u1ee9 hai ch\u1ee9a <code>n</code> s\u1ed1 nguy\u00ean c\u1ee7a <code>prices</code></li> </ul> <p>Output</p> <ul> <li>G\u1ed3m m\u1ed9t d\u00f2ng duy nh\u1ea5t l\u00e0 k\u1ebft qu\u1ea3 c\u1ee7a b\u00e0i to\u00e1n</li> </ul> <p>R\u00e0ng bu\u1ed9c</p> <ul> <li>\\(1 \\leq\\) <code>n</code> \\(\\leq 5 \\times 10^4\\)</li> <li>\\(1 \\leq\\) <code>prices[i]</code> \\(&lt; 5 \\times 10^4\\)</li> <li>\\(0 \\leq\\) <code>fee</code> \\(&lt; 5 \\times 10^4\\)</li> </ul> <p>V\u00ed d\u1ee5</p> <p>V\u00ed d\u1ee5 1</p> <p>Input<pre><code>6 2\n1 3 2 8 4 9\n</code></pre> Output<pre><code>8\n</code></pre> Gi\u1ea3i th\u00edch: L\u1ee3i nhu\u1eadn t\u1ed1i \u0111a \u0111\u1ea1t \u0111\u01b0\u1ee3c b\u1eb1ng c\u00e1ch:</p> <ul> <li>Mua \u1edf ng\u00e0y 0, gi\u00e1 b\u1eb1ng \\(1\\)</li> <li>B\u00e1n \u1edf ng\u00e0y 3, gi\u00e1 b\u1eb1ng \\(8\\)</li> <li>Mua \u1edf ng\u00e0y 4, gi\u00e1 b\u1eb1ng \\(4\\)</li> <li>B\u00e1n \u1edf ng\u00e0y 5, gi\u00e1 b\u1eb1ng \\(9\\)</li> </ul> <p>T\u1ed5ng l\u1ee3i nhu\u1eadn l\u00e0 \\(((8 - 1) - 2) + ((9 - 4) - 2) = 8\\).</p> <p>V\u00ed d\u1ee5 2</p> <p>Input<pre><code>6 3\n1 3 7 5 10 3\n</code></pre> Output<pre><code>6\n</code></pre></p> Link n\u1ed9p b\u00e0i <p> 714.\u00a0Best Time to Buy and Sell Stock with Transaction Fee</p> Solution <p>Quy ho\u1ea1ch \u0111\u1ed9ng: G\u1ecdi <code>free[i]</code> l\u00e0 l\u1ee3i nhu\u1eadn l\u1edbn nh\u1ea5t n\u1ebfu kh\u00f4ng gi\u1eef c\u1ed5 phi\u1ebfu v\u00e0o ng\u00e0y th\u1ee9 <code>i</code> v\u00e0 <code>hold[i]</code> l\u00e0 l\u1ee3i nhu\u1eadn l\u1edbn nh\u1ea5t n\u1ebfu gi\u1eef c\u1ed5 phi\u1ebfu v\u00e0o ng\u00e0y th\u1ee9 <code>i</code>.</p> <p>C\u00f4ng th\u1ee9c quy ho\u1ea1ch \u0111\u1ed9ng:</p> <ul> <li><code>free[i] = max(free[i - 1], hold[i - 1] + prices[i] - fee)</code> (Ho\u1eb7c tr\u01b0\u1edbc \u0111\u00f3 \u0111ang kh\u00f4ng gi\u1eef c\u1ed5 phi\u1ebfu v\u00e0 sau \u0111\u00f3 kh\u00f4ng l\u00e0m g\u00ec v\u00e0o ng\u00e0y th\u1ee9 <code>i</code>, ho\u1eb7c b\u00e1n c\u1ed5 phi\u1ebfu \u0111\u00f3 v\u00e0o ng\u00e0y th\u1ee9 <code>i</code>);</li> <li><code>hold[i] = max(hold[i - 1], free[i - 1] - prices[i]</code> (Ho\u1eb7c tr\u01b0\u1edbc \u0111\u00f3 \u0111ang gi\u1eef c\u1ed5 phi\u1ebfu v\u00e0 sau \u0111\u00f3 kh\u00f4ng l\u00e0m g\u00ec v\u00e0o ng\u00e0y th\u1ee9 <code>i</code>, ho\u1eb7c tr\u01b0\u1edbc \u0111\u00f3 \u0111ang kh\u00f4ng gi\u1eef c\u1ed5 phi\u1ebfu v\u00e0 mua c\u1ed5 phi\u1ebfu v\u00e0o ng\u00e0y th\u1ee9 <code>i</code>.</li> </ul> <p>K\u1ebft qu\u1ea3 b\u00e0i to\u00e1n l\u00e0 <code>free[n - 1]</code> (c\u00e1c ch\u1ec9 s\u1ed1 \u0111\u01b0\u1ee3c \u0111\u00e1nh s\u1ed1 b\u1eaft \u0111\u1ea7u t\u1eeb \\(0\\)).</p> <p>V\u00ec <code>free[i]</code> v\u00e0 <code>hold[i]</code> ch\u1ec9 ph\u1ee5 thu\u1ed9c v\u00e0o <code>free[i - 1]</code> v\u00e0 <code>hold[i - 1]</code>, n\u00ean thay v\u00ec d\u00f9ng m\u1ea3ng \u0111\u1ec3 l\u01b0u th\u00ec ta ch\u1ec9 c\u1ea7n m\u1ed9t bi\u1ebfn <code>free</code> \u0111\u1ec3 l\u01b0u l\u1ee3i nhu\u1eadn l\u1edbn nh\u1ea5t n\u1ebfu kh\u00f4ng gi\u1eef c\u1ed5 phi\u1ebfu v\u00e0o ng\u00e0y th\u1ee9 <code>i</code> v\u00e0 m\u1ed9t bi\u1ebfn <code>hold</code> \u0111\u1ec3 l\u01b0u l\u1ee3i nhu\u1eadn l\u1edbn nh\u1ea5t n\u1ebfu gi\u1eef c\u1ed5 phi\u1ebfu v\u00e0o ng\u00e0y th\u1ee9 <code>i</code>. L\u00fac duy\u1ec7t ta s\u1ebd c\u1eadp nh\u1eadt 2 bi\u1ebfn n\u00e0y.</p> <p>\u0110\u1ed9 ph\u1ee9c t\u1ea1p \\(\\text{O}(n)\\).</p> Code  C++ Python <pre><code>class Solution {\npublic:\n    int maxProfit(vector&lt;int&gt;&amp; prices, int fee) {\n        int n = prices.size();\n        int free = 0, hold = -prices[0];\n\n        for (int i = 1; i &lt; n; i++) {\n            int tmp = hold;\n            hold = max(hold, free - prices[i]);\n            free = max(free, tmp + prices[i] - fee);\n        }\n\n        return free;\n    }\n};\n</code></pre> <pre><code>class Solution:\ndef maxProfit(self, prices: List[int], fee: int) -&gt; int:\n    free = 0\n    hold = -prices[0]\n\n    for i in range(1, len(prices)):\n        hold, free = max(hold, free - prices[i]), max(free, hold + prices[i] - fee)\n\n    return free\n</code></pre>"},{"location":"blog/category/flag_gb/","title":"\ud83c\uddec\ud83c\udde7","text":""},{"location":"blog/category/computer-system-design/","title":"System Design","text":""},{"location":"blog/category/flag_vn/","title":"\ud83c\uddfb\ud83c\uddf3","text":""},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#cap-theorem","title":"CAP theorem","text":"<ul> <li>The CAP theorem</li> </ul>"},{"location":"tags/#hadoop","title":"Hadoop","text":"<ul> <li>Gi\u1edbi thi\u1ec7u v\u1ec1 Apache Hadoop</li> </ul>"},{"location":"tags/#load-balancing","title":"Load Balancing","text":"<ul> <li>Load Balancing Algorithms</li> </ul>"}]}